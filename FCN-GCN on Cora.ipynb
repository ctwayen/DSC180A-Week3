{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# author: Xinrui Zhan\n",
    "# time: 2020/10\n",
    "# code based on this tutorial: \n",
    "# https://medium.com/@BorisAKnyazev/tutorial-on-graph-neural-networks-for-computer-vision-and-beyond-part-1-3d9fada3b80d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import section\n",
    "from __future__ import print_function\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0\n",
      "10.0.130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@copy from https://github.com/bknyaz/examples/blob/master/fc_vs_graph_train.py\n",
    "class FNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FNet, self).__init__()\n",
    "        self.fc = nn.Linear(1433, 7, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x.view(x.size(0), -1))\n",
    "            \n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        #print(data.type())\n",
    "        data = data.float()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test(model, device, test_loader, train_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct_test = 0\n",
    "    correct_train = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            data = data.float()\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct_test += pred.eq(target.view_as(pred)).sum().item()\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            data = data.float()\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct_train += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print(\n",
    "        '\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, correct_test, len(test_loader.dataset),\n",
    "            100. * correct_test / len(test_loader.dataset)))\n",
    "    return (100. * correct_test / len(test_loader.dataset), 100. * correct_train / len(train_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2708, 1433)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2708,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2708,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = pd.read_csv('cora.content', header=None,delimiter='\\t')\n",
    "features = features.rename(columns={0: 'id', 1434: 'target'}).to_numpy()\n",
    "X = features[:, 1: -1].astype(int)\n",
    "y = features[:, -1]\n",
    "display(X.shape, y.shape)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "y = le.transform(y)\n",
    "display(y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_x = torch.tensor(X_train) # transform to torch tensor\n",
    "train_y = torch.from_numpy(y_train)\n",
    "train_y = train_y.type(torch.long)\n",
    "train_x = train_x.type(torch.long)\n",
    "\n",
    "test_x = torch.tensor(X_test) # transform to torch tensor\n",
    "test_y = torch.from_numpy(y_test)\n",
    "test_y = test_y.type(torch.long)\n",
    "test_x = test_x.type(torch.long)\n",
    "\n",
    "cora_train_dataset = TensorDataset(train_x,train_y)\n",
    "cora_test_dataset = TensorDataset(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNet(\n",
      "  (fc): Linear(in_features=1433, out_features=7, bias=False)\n",
      ")\n",
      "number of trainable parameters: 10031\n",
      "Train Epoch: 1 [0/2166 (0%)]\tLoss: 1.946968\n",
      "Train Epoch: 1 [640/2166 (29%)]\tLoss: 1.940711\n",
      "Train Epoch: 1 [1280/2166 (59%)]\tLoss: 1.947083\n",
      "Train Epoch: 1 [1920/2166 (88%)]\tLoss: 1.957698\n",
      "\n",
      "Test set: Average loss: 1.9348, Accuracy: 101/542 (19%)\n",
      "\n",
      "Train Epoch: 2 [0/2166 (0%)]\tLoss: 1.933833\n",
      "Train Epoch: 2 [640/2166 (29%)]\tLoss: 1.938287\n",
      "Train Epoch: 2 [1280/2166 (59%)]\tLoss: 1.922541\n",
      "Train Epoch: 2 [1920/2166 (88%)]\tLoss: 1.919498\n",
      "\n",
      "Test set: Average loss: 1.9185, Accuracy: 163/542 (30%)\n",
      "\n",
      "Train Epoch: 3 [0/2166 (0%)]\tLoss: 1.911649\n",
      "Train Epoch: 3 [640/2166 (29%)]\tLoss: 1.914122\n",
      "Train Epoch: 3 [1280/2166 (59%)]\tLoss: 1.915117\n",
      "Train Epoch: 3 [1920/2166 (88%)]\tLoss: 1.889410\n",
      "\n",
      "Test set: Average loss: 1.9035, Accuracy: 204/542 (38%)\n",
      "\n",
      "Train Epoch: 4 [0/2166 (0%)]\tLoss: 1.896082\n",
      "Train Epoch: 4 [640/2166 (29%)]\tLoss: 1.900636\n",
      "Train Epoch: 4 [1280/2166 (59%)]\tLoss: 1.899613\n",
      "Train Epoch: 4 [1920/2166 (88%)]\tLoss: 1.882269\n",
      "\n",
      "Test set: Average loss: 1.8891, Accuracy: 235/542 (43%)\n",
      "\n",
      "Train Epoch: 5 [0/2166 (0%)]\tLoss: 1.888121\n",
      "Train Epoch: 5 [640/2166 (29%)]\tLoss: 1.868600\n",
      "Train Epoch: 5 [1280/2166 (59%)]\tLoss: 1.877512\n",
      "Train Epoch: 5 [1920/2166 (88%)]\tLoss: 1.878869\n",
      "\n",
      "Test set: Average loss: 1.8753, Accuracy: 241/542 (44%)\n",
      "\n",
      "Train Epoch: 6 [0/2166 (0%)]\tLoss: 1.851474\n",
      "Train Epoch: 6 [640/2166 (29%)]\tLoss: 1.864684\n",
      "Train Epoch: 6 [1280/2166 (59%)]\tLoss: 1.859637\n",
      "Train Epoch: 6 [1920/2166 (88%)]\tLoss: 1.852046\n",
      "\n",
      "Test set: Average loss: 1.8623, Accuracy: 247/542 (46%)\n",
      "\n",
      "Train Epoch: 7 [0/2166 (0%)]\tLoss: 1.852742\n",
      "Train Epoch: 7 [640/2166 (29%)]\tLoss: 1.842508\n",
      "Train Epoch: 7 [1280/2166 (59%)]\tLoss: 1.844913\n",
      "Train Epoch: 7 [1920/2166 (88%)]\tLoss: 1.829250\n",
      "\n",
      "Test set: Average loss: 1.8501, Accuracy: 246/542 (45%)\n",
      "\n",
      "Train Epoch: 8 [0/2166 (0%)]\tLoss: 1.821033\n",
      "Train Epoch: 8 [640/2166 (29%)]\tLoss: 1.841928\n",
      "Train Epoch: 8 [1280/2166 (59%)]\tLoss: 1.850945\n",
      "Train Epoch: 8 [1920/2166 (88%)]\tLoss: 1.832726\n",
      "\n",
      "Test set: Average loss: 1.8385, Accuracy: 250/542 (46%)\n",
      "\n",
      "Train Epoch: 9 [0/2166 (0%)]\tLoss: 1.838263\n",
      "Train Epoch: 9 [640/2166 (29%)]\tLoss: 1.825889\n",
      "Train Epoch: 9 [1280/2166 (59%)]\tLoss: 1.826025\n",
      "Train Epoch: 9 [1920/2166 (88%)]\tLoss: 1.809718\n",
      "\n",
      "Test set: Average loss: 1.8275, Accuracy: 250/542 (46%)\n",
      "\n",
      "Train Epoch: 10 [0/2166 (0%)]\tLoss: 1.831103\n",
      "Train Epoch: 10 [640/2166 (29%)]\tLoss: 1.804562\n",
      "Train Epoch: 10 [1280/2166 (59%)]\tLoss: 1.818669\n",
      "Train Epoch: 10 [1920/2166 (88%)]\tLoss: 1.811174\n",
      "\n",
      "Test set: Average loss: 1.8171, Accuracy: 252/542 (46%)\n",
      "\n",
      "Train Epoch: 11 [0/2166 (0%)]\tLoss: 1.824009\n",
      "Train Epoch: 11 [640/2166 (29%)]\tLoss: 1.787558\n",
      "Train Epoch: 11 [1280/2166 (59%)]\tLoss: 1.788782\n",
      "Train Epoch: 11 [1920/2166 (88%)]\tLoss: 1.793593\n",
      "\n",
      "Test set: Average loss: 1.8071, Accuracy: 250/542 (46%)\n",
      "\n",
      "Train Epoch: 12 [0/2166 (0%)]\tLoss: 1.811030\n",
      "Train Epoch: 12 [640/2166 (29%)]\tLoss: 1.794938\n",
      "Train Epoch: 12 [1280/2166 (59%)]\tLoss: 1.771105\n",
      "Train Epoch: 12 [1920/2166 (88%)]\tLoss: 1.763390\n",
      "\n",
      "Test set: Average loss: 1.7974, Accuracy: 254/542 (47%)\n",
      "\n",
      "Train Epoch: 13 [0/2166 (0%)]\tLoss: 1.785173\n",
      "Train Epoch: 13 [640/2166 (29%)]\tLoss: 1.770381\n",
      "Train Epoch: 13 [1280/2166 (59%)]\tLoss: 1.753240\n",
      "Train Epoch: 13 [1920/2166 (88%)]\tLoss: 1.766938\n",
      "\n",
      "Test set: Average loss: 1.7883, Accuracy: 254/542 (47%)\n",
      "\n",
      "Train Epoch: 14 [0/2166 (0%)]\tLoss: 1.782623\n",
      "Train Epoch: 14 [640/2166 (29%)]\tLoss: 1.740760\n",
      "Train Epoch: 14 [1280/2166 (59%)]\tLoss: 1.737360\n",
      "Train Epoch: 14 [1920/2166 (88%)]\tLoss: 1.759059\n",
      "\n",
      "Test set: Average loss: 1.7796, Accuracy: 255/542 (47%)\n",
      "\n",
      "Train Epoch: 15 [0/2166 (0%)]\tLoss: 1.767001\n",
      "Train Epoch: 15 [640/2166 (29%)]\tLoss: 1.769917\n",
      "Train Epoch: 15 [1280/2166 (59%)]\tLoss: 1.757972\n",
      "Train Epoch: 15 [1920/2166 (88%)]\tLoss: 1.758641\n",
      "\n",
      "Test set: Average loss: 1.7713, Accuracy: 253/542 (47%)\n",
      "\n",
      "Train Epoch: 16 [0/2166 (0%)]\tLoss: 1.759994\n",
      "Train Epoch: 16 [640/2166 (29%)]\tLoss: 1.751916\n",
      "Train Epoch: 16 [1280/2166 (59%)]\tLoss: 1.767209\n",
      "Train Epoch: 16 [1920/2166 (88%)]\tLoss: 1.743972\n",
      "\n",
      "Test set: Average loss: 1.7633, Accuracy: 257/542 (47%)\n",
      "\n",
      "Train Epoch: 17 [0/2166 (0%)]\tLoss: 1.743172\n",
      "Train Epoch: 17 [640/2166 (29%)]\tLoss: 1.728862\n",
      "Train Epoch: 17 [1280/2166 (59%)]\tLoss: 1.750522\n",
      "Train Epoch: 17 [1920/2166 (88%)]\tLoss: 1.747915\n",
      "\n",
      "Test set: Average loss: 1.7558, Accuracy: 263/542 (49%)\n",
      "\n",
      "Train Epoch: 18 [0/2166 (0%)]\tLoss: 1.735755\n",
      "Train Epoch: 18 [640/2166 (29%)]\tLoss: 1.716105\n",
      "Train Epoch: 18 [1280/2166 (59%)]\tLoss: 1.745111\n",
      "Train Epoch: 18 [1920/2166 (88%)]\tLoss: 1.747205\n",
      "\n",
      "Test set: Average loss: 1.7484, Accuracy: 265/542 (49%)\n",
      "\n",
      "Train Epoch: 19 [0/2166 (0%)]\tLoss: 1.703754\n",
      "Train Epoch: 19 [640/2166 (29%)]\tLoss: 1.724031\n",
      "Train Epoch: 19 [1280/2166 (59%)]\tLoss: 1.706783\n",
      "Train Epoch: 19 [1920/2166 (88%)]\tLoss: 1.721761\n",
      "\n",
      "Test set: Average loss: 1.7413, Accuracy: 266/542 (49%)\n",
      "\n",
      "Train Epoch: 20 [0/2166 (0%)]\tLoss: 1.709320\n",
      "Train Epoch: 20 [640/2166 (29%)]\tLoss: 1.718920\n",
      "Train Epoch: 20 [1280/2166 (59%)]\tLoss: 1.688134\n",
      "Train Epoch: 20 [1920/2166 (88%)]\tLoss: 1.696324\n",
      "\n",
      "Test set: Average loss: 1.7347, Accuracy: 267/542 (49%)\n",
      "\n",
      "Train Epoch: 21 [0/2166 (0%)]\tLoss: 1.670648\n",
      "Train Epoch: 21 [640/2166 (29%)]\tLoss: 1.724509\n",
      "Train Epoch: 21 [1280/2166 (59%)]\tLoss: 1.725929\n",
      "Train Epoch: 21 [1920/2166 (88%)]\tLoss: 1.688115\n",
      "\n",
      "Test set: Average loss: 1.7282, Accuracy: 269/542 (50%)\n",
      "\n",
      "Train Epoch: 22 [0/2166 (0%)]\tLoss: 1.687642\n",
      "Train Epoch: 22 [640/2166 (29%)]\tLoss: 1.715133\n",
      "Train Epoch: 22 [1280/2166 (59%)]\tLoss: 1.681472\n",
      "Train Epoch: 22 [1920/2166 (88%)]\tLoss: 1.690893\n",
      "\n",
      "Test set: Average loss: 1.7220, Accuracy: 275/542 (51%)\n",
      "\n",
      "Train Epoch: 23 [0/2166 (0%)]\tLoss: 1.706164\n",
      "Train Epoch: 23 [640/2166 (29%)]\tLoss: 1.701969\n",
      "Train Epoch: 23 [1280/2166 (59%)]\tLoss: 1.701008\n",
      "Train Epoch: 23 [1920/2166 (88%)]\tLoss: 1.683185\n",
      "\n",
      "Test set: Average loss: 1.7161, Accuracy: 276/542 (51%)\n",
      "\n",
      "Train Epoch: 24 [0/2166 (0%)]\tLoss: 1.691547\n",
      "Train Epoch: 24 [640/2166 (29%)]\tLoss: 1.666380\n",
      "Train Epoch: 24 [1280/2166 (59%)]\tLoss: 1.661199\n",
      "Train Epoch: 24 [1920/2166 (88%)]\tLoss: 1.677071\n",
      "\n",
      "Test set: Average loss: 1.7103, Accuracy: 279/542 (51%)\n",
      "\n",
      "Train Epoch: 25 [0/2166 (0%)]\tLoss: 1.710374\n",
      "Train Epoch: 25 [640/2166 (29%)]\tLoss: 1.701286\n",
      "Train Epoch: 25 [1280/2166 (59%)]\tLoss: 1.674649\n",
      "Train Epoch: 25 [1920/2166 (88%)]\tLoss: 1.626506\n",
      "\n",
      "Test set: Average loss: 1.7047, Accuracy: 279/542 (51%)\n",
      "\n",
      "Train Epoch: 26 [0/2166 (0%)]\tLoss: 1.671687\n",
      "Train Epoch: 26 [640/2166 (29%)]\tLoss: 1.726530\n",
      "Train Epoch: 26 [1280/2166 (59%)]\tLoss: 1.685035\n",
      "Train Epoch: 26 [1920/2166 (88%)]\tLoss: 1.691140\n",
      "\n",
      "Test set: Average loss: 1.6993, Accuracy: 281/542 (52%)\n",
      "\n",
      "Train Epoch: 27 [0/2166 (0%)]\tLoss: 1.647024\n",
      "Train Epoch: 27 [640/2166 (29%)]\tLoss: 1.683497\n",
      "Train Epoch: 27 [1280/2166 (59%)]\tLoss: 1.665373\n",
      "Train Epoch: 27 [1920/2166 (88%)]\tLoss: 1.647630\n",
      "\n",
      "Test set: Average loss: 1.6941, Accuracy: 283/542 (52%)\n",
      "\n",
      "Train Epoch: 28 [0/2166 (0%)]\tLoss: 1.661265\n",
      "Train Epoch: 28 [640/2166 (29%)]\tLoss: 1.630248\n",
      "Train Epoch: 28 [1280/2166 (59%)]\tLoss: 1.638135\n",
      "Train Epoch: 28 [1920/2166 (88%)]\tLoss: 1.630736\n",
      "\n",
      "Test set: Average loss: 1.6890, Accuracy: 286/542 (53%)\n",
      "\n",
      "Train Epoch: 29 [0/2166 (0%)]\tLoss: 1.696458\n",
      "Train Epoch: 29 [640/2166 (29%)]\tLoss: 1.631685\n",
      "Train Epoch: 29 [1280/2166 (59%)]\tLoss: 1.661981\n",
      "Train Epoch: 29 [1920/2166 (88%)]\tLoss: 1.693040\n",
      "\n",
      "Test set: Average loss: 1.6841, Accuracy: 288/542 (53%)\n",
      "\n",
      "Train Epoch: 30 [0/2166 (0%)]\tLoss: 1.657428\n",
      "Train Epoch: 30 [640/2166 (29%)]\tLoss: 1.663161\n",
      "Train Epoch: 30 [1280/2166 (59%)]\tLoss: 1.655214\n",
      "Train Epoch: 30 [1920/2166 (88%)]\tLoss: 1.637652\n",
      "\n",
      "Test set: Average loss: 1.6796, Accuracy: 291/542 (54%)\n",
      "\n",
      "Train Epoch: 31 [0/2166 (0%)]\tLoss: 1.647400\n",
      "Train Epoch: 31 [640/2166 (29%)]\tLoss: 1.671930\n",
      "Train Epoch: 31 [1280/2166 (59%)]\tLoss: 1.670049\n",
      "Train Epoch: 31 [1920/2166 (88%)]\tLoss: 1.663451\n",
      "\n",
      "Test set: Average loss: 1.6750, Accuracy: 294/542 (54%)\n",
      "\n",
      "Train Epoch: 32 [0/2166 (0%)]\tLoss: 1.667191\n",
      "Train Epoch: 32 [640/2166 (29%)]\tLoss: 1.626639\n",
      "Train Epoch: 32 [1280/2166 (59%)]\tLoss: 1.643469\n",
      "Train Epoch: 32 [1920/2166 (88%)]\tLoss: 1.683706\n",
      "\n",
      "Test set: Average loss: 1.6705, Accuracy: 297/542 (55%)\n",
      "\n",
      "Train Epoch: 33 [0/2166 (0%)]\tLoss: 1.648294\n",
      "Train Epoch: 33 [640/2166 (29%)]\tLoss: 1.610101\n",
      "Train Epoch: 33 [1280/2166 (59%)]\tLoss: 1.642445\n",
      "Train Epoch: 33 [1920/2166 (88%)]\tLoss: 1.642580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.6661, Accuracy: 298/542 (55%)\n",
      "\n",
      "Train Epoch: 34 [0/2166 (0%)]\tLoss: 1.580573\n",
      "Train Epoch: 34 [640/2166 (29%)]\tLoss: 1.600926\n",
      "Train Epoch: 34 [1280/2166 (59%)]\tLoss: 1.626996\n",
      "Train Epoch: 34 [1920/2166 (88%)]\tLoss: 1.629581\n",
      "\n",
      "Test set: Average loss: 1.6620, Accuracy: 300/542 (55%)\n",
      "\n",
      "Train Epoch: 35 [0/2166 (0%)]\tLoss: 1.620896\n",
      "Train Epoch: 35 [640/2166 (29%)]\tLoss: 1.596379\n",
      "Train Epoch: 35 [1280/2166 (59%)]\tLoss: 1.685265\n",
      "Train Epoch: 35 [1920/2166 (88%)]\tLoss: 1.594895\n",
      "\n",
      "Test set: Average loss: 1.6580, Accuracy: 300/542 (55%)\n",
      "\n",
      "Train Epoch: 36 [0/2166 (0%)]\tLoss: 1.660198\n",
      "Train Epoch: 36 [640/2166 (29%)]\tLoss: 1.566050\n",
      "Train Epoch: 36 [1280/2166 (59%)]\tLoss: 1.606051\n",
      "Train Epoch: 36 [1920/2166 (88%)]\tLoss: 1.638267\n",
      "\n",
      "Test set: Average loss: 1.6541, Accuracy: 303/542 (56%)\n",
      "\n",
      "Train Epoch: 37 [0/2166 (0%)]\tLoss: 1.623767\n",
      "Train Epoch: 37 [640/2166 (29%)]\tLoss: 1.621958\n",
      "Train Epoch: 37 [1280/2166 (59%)]\tLoss: 1.663976\n",
      "Train Epoch: 37 [1920/2166 (88%)]\tLoss: 1.589161\n",
      "\n",
      "Test set: Average loss: 1.6503, Accuracy: 303/542 (56%)\n",
      "\n",
      "Train Epoch: 38 [0/2166 (0%)]\tLoss: 1.652883\n",
      "Train Epoch: 38 [640/2166 (29%)]\tLoss: 1.577661\n",
      "Train Epoch: 38 [1280/2166 (59%)]\tLoss: 1.577875\n",
      "Train Epoch: 38 [1920/2166 (88%)]\tLoss: 1.639949\n",
      "\n",
      "Test set: Average loss: 1.6467, Accuracy: 304/542 (56%)\n",
      "\n",
      "Train Epoch: 39 [0/2166 (0%)]\tLoss: 1.558239\n",
      "Train Epoch: 39 [640/2166 (29%)]\tLoss: 1.634516\n",
      "Train Epoch: 39 [1280/2166 (59%)]\tLoss: 1.635614\n",
      "Train Epoch: 39 [1920/2166 (88%)]\tLoss: 1.564969\n",
      "\n",
      "Test set: Average loss: 1.6430, Accuracy: 306/542 (56%)\n",
      "\n",
      "Train Epoch: 40 [0/2166 (0%)]\tLoss: 1.575025\n",
      "Train Epoch: 40 [640/2166 (29%)]\tLoss: 1.603848\n",
      "Train Epoch: 40 [1280/2166 (59%)]\tLoss: 1.653316\n",
      "Train Epoch: 40 [1920/2166 (88%)]\tLoss: 1.582882\n",
      "\n",
      "Test set: Average loss: 1.6396, Accuracy: 306/542 (56%)\n",
      "\n",
      "Train Epoch: 41 [0/2166 (0%)]\tLoss: 1.613957\n",
      "Train Epoch: 41 [640/2166 (29%)]\tLoss: 1.620025\n",
      "Train Epoch: 41 [1280/2166 (59%)]\tLoss: 1.572228\n",
      "Train Epoch: 41 [1920/2166 (88%)]\tLoss: 1.629445\n",
      "\n",
      "Test set: Average loss: 1.6362, Accuracy: 309/542 (57%)\n",
      "\n",
      "Train Epoch: 42 [0/2166 (0%)]\tLoss: 1.578979\n",
      "Train Epoch: 42 [640/2166 (29%)]\tLoss: 1.612013\n",
      "Train Epoch: 42 [1280/2166 (59%)]\tLoss: 1.606387\n",
      "Train Epoch: 42 [1920/2166 (88%)]\tLoss: 1.569761\n",
      "\n",
      "Test set: Average loss: 1.6329, Accuracy: 312/542 (58%)\n",
      "\n",
      "Train Epoch: 43 [0/2166 (0%)]\tLoss: 1.627732\n",
      "Train Epoch: 43 [640/2166 (29%)]\tLoss: 1.562118\n",
      "Train Epoch: 43 [1280/2166 (59%)]\tLoss: 1.576868\n",
      "Train Epoch: 43 [1920/2166 (88%)]\tLoss: 1.604562\n",
      "\n",
      "Test set: Average loss: 1.6297, Accuracy: 312/542 (58%)\n",
      "\n",
      "Train Epoch: 44 [0/2166 (0%)]\tLoss: 1.629689\n",
      "Train Epoch: 44 [640/2166 (29%)]\tLoss: 1.637498\n",
      "Train Epoch: 44 [1280/2166 (59%)]\tLoss: 1.592369\n",
      "Train Epoch: 44 [1920/2166 (88%)]\tLoss: 1.565588\n",
      "\n",
      "Test set: Average loss: 1.6267, Accuracy: 311/542 (57%)\n",
      "\n",
      "Train Epoch: 45 [0/2166 (0%)]\tLoss: 1.577530\n",
      "Train Epoch: 45 [640/2166 (29%)]\tLoss: 1.572984\n",
      "Train Epoch: 45 [1280/2166 (59%)]\tLoss: 1.633760\n",
      "Train Epoch: 45 [1920/2166 (88%)]\tLoss: 1.619446\n",
      "\n",
      "Test set: Average loss: 1.6235, Accuracy: 313/542 (58%)\n",
      "\n",
      "Train Epoch: 46 [0/2166 (0%)]\tLoss: 1.628999\n",
      "Train Epoch: 46 [640/2166 (29%)]\tLoss: 1.633641\n",
      "Train Epoch: 46 [1280/2166 (59%)]\tLoss: 1.574749\n",
      "Train Epoch: 46 [1920/2166 (88%)]\tLoss: 1.599934\n",
      "\n",
      "Test set: Average loss: 1.6206, Accuracy: 313/542 (58%)\n",
      "\n",
      "Train Epoch: 47 [0/2166 (0%)]\tLoss: 1.642447\n",
      "Train Epoch: 47 [640/2166 (29%)]\tLoss: 1.624821\n",
      "Train Epoch: 47 [1280/2166 (59%)]\tLoss: 1.654664\n",
      "Train Epoch: 47 [1920/2166 (88%)]\tLoss: 1.555602\n",
      "\n",
      "Test set: Average loss: 1.6179, Accuracy: 313/542 (58%)\n",
      "\n",
      "Train Epoch: 48 [0/2166 (0%)]\tLoss: 1.556639\n",
      "Train Epoch: 48 [640/2166 (29%)]\tLoss: 1.644637\n",
      "Train Epoch: 48 [1280/2166 (59%)]\tLoss: 1.558933\n",
      "Train Epoch: 48 [1920/2166 (88%)]\tLoss: 1.563560\n",
      "\n",
      "Test set: Average loss: 1.6150, Accuracy: 314/542 (58%)\n",
      "\n",
      "Train Epoch: 49 [0/2166 (0%)]\tLoss: 1.648981\n",
      "Train Epoch: 49 [640/2166 (29%)]\tLoss: 1.590417\n",
      "Train Epoch: 49 [1280/2166 (59%)]\tLoss: 1.593904\n",
      "Train Epoch: 49 [1920/2166 (88%)]\tLoss: 1.580590\n",
      "\n",
      "Test set: Average loss: 1.6122, Accuracy: 314/542 (58%)\n",
      "\n",
      "Train Epoch: 50 [0/2166 (0%)]\tLoss: 1.562831\n",
      "Train Epoch: 50 [640/2166 (29%)]\tLoss: 1.611546\n",
      "Train Epoch: 50 [1280/2166 (59%)]\tLoss: 1.582987\n",
      "Train Epoch: 50 [1920/2166 (88%)]\tLoss: 1.598524\n",
      "\n",
      "Test set: Average loss: 1.6095, Accuracy: 314/542 (58%)\n",
      "\n",
      "Train Epoch: 51 [0/2166 (0%)]\tLoss: 1.605739\n",
      "Train Epoch: 51 [640/2166 (29%)]\tLoss: 1.519306\n",
      "Train Epoch: 51 [1280/2166 (59%)]\tLoss: 1.559838\n",
      "Train Epoch: 51 [1920/2166 (88%)]\tLoss: 1.621289\n",
      "\n",
      "Test set: Average loss: 1.6069, Accuracy: 314/542 (58%)\n",
      "\n",
      "Train Epoch: 52 [0/2166 (0%)]\tLoss: 1.595023\n",
      "Train Epoch: 52 [640/2166 (29%)]\tLoss: 1.546927\n",
      "Train Epoch: 52 [1280/2166 (59%)]\tLoss: 1.609982\n",
      "Train Epoch: 52 [1920/2166 (88%)]\tLoss: 1.584940\n",
      "\n",
      "Test set: Average loss: 1.6043, Accuracy: 315/542 (58%)\n",
      "\n",
      "Train Epoch: 53 [0/2166 (0%)]\tLoss: 1.617115\n",
      "Train Epoch: 53 [640/2166 (29%)]\tLoss: 1.528213\n",
      "Train Epoch: 53 [1280/2166 (59%)]\tLoss: 1.506069\n",
      "Train Epoch: 53 [1920/2166 (88%)]\tLoss: 1.591942\n",
      "\n",
      "Test set: Average loss: 1.6019, Accuracy: 315/542 (58%)\n",
      "\n",
      "Train Epoch: 54 [0/2166 (0%)]\tLoss: 1.551785\n",
      "Train Epoch: 54 [640/2166 (29%)]\tLoss: 1.590401\n",
      "Train Epoch: 54 [1280/2166 (59%)]\tLoss: 1.608972\n",
      "Train Epoch: 54 [1920/2166 (88%)]\tLoss: 1.610062\n",
      "\n",
      "Test set: Average loss: 1.5994, Accuracy: 316/542 (58%)\n",
      "\n",
      "Train Epoch: 55 [0/2166 (0%)]\tLoss: 1.588403\n",
      "Train Epoch: 55 [640/2166 (29%)]\tLoss: 1.589184\n",
      "Train Epoch: 55 [1280/2166 (59%)]\tLoss: 1.567187\n",
      "Train Epoch: 55 [1920/2166 (88%)]\tLoss: 1.576330\n",
      "\n",
      "Test set: Average loss: 1.5972, Accuracy: 316/542 (58%)\n",
      "\n",
      "Train Epoch: 56 [0/2166 (0%)]\tLoss: 1.524687\n",
      "Train Epoch: 56 [640/2166 (29%)]\tLoss: 1.531785\n",
      "Train Epoch: 56 [1280/2166 (59%)]\tLoss: 1.637346\n",
      "Train Epoch: 56 [1920/2166 (88%)]\tLoss: 1.571524\n",
      "\n",
      "Test set: Average loss: 1.5947, Accuracy: 316/542 (58%)\n",
      "\n",
      "Train Epoch: 57 [0/2166 (0%)]\tLoss: 1.546784\n",
      "Train Epoch: 57 [640/2166 (29%)]\tLoss: 1.607390\n",
      "Train Epoch: 57 [1280/2166 (59%)]\tLoss: 1.525542\n",
      "Train Epoch: 57 [1920/2166 (88%)]\tLoss: 1.566788\n",
      "\n",
      "Test set: Average loss: 1.5924, Accuracy: 315/542 (58%)\n",
      "\n",
      "Train Epoch: 58 [0/2166 (0%)]\tLoss: 1.595671\n",
      "Train Epoch: 58 [640/2166 (29%)]\tLoss: 1.623418\n",
      "Train Epoch: 58 [1280/2166 (59%)]\tLoss: 1.523125\n",
      "Train Epoch: 58 [1920/2166 (88%)]\tLoss: 1.519830\n",
      "\n",
      "Test set: Average loss: 1.5904, Accuracy: 317/542 (58%)\n",
      "\n",
      "Train Epoch: 59 [0/2166 (0%)]\tLoss: 1.569821\n",
      "Train Epoch: 59 [640/2166 (29%)]\tLoss: 1.509809\n",
      "Train Epoch: 59 [1280/2166 (59%)]\tLoss: 1.623227\n",
      "Train Epoch: 59 [1920/2166 (88%)]\tLoss: 1.520151\n",
      "\n",
      "Test set: Average loss: 1.5881, Accuracy: 317/542 (58%)\n",
      "\n",
      "Train Epoch: 60 [0/2166 (0%)]\tLoss: 1.563635\n",
      "Train Epoch: 60 [640/2166 (29%)]\tLoss: 1.534737\n",
      "Train Epoch: 60 [1280/2166 (59%)]\tLoss: 1.531313\n",
      "Train Epoch: 60 [1920/2166 (88%)]\tLoss: 1.569704\n",
      "\n",
      "Test set: Average loss: 1.5860, Accuracy: 318/542 (59%)\n",
      "\n",
      "Train Epoch: 61 [0/2166 (0%)]\tLoss: 1.541785\n",
      "Train Epoch: 61 [640/2166 (29%)]\tLoss: 1.532565\n",
      "Train Epoch: 61 [1280/2166 (59%)]\tLoss: 1.582980\n",
      "Train Epoch: 61 [1920/2166 (88%)]\tLoss: 1.577674\n",
      "\n",
      "Test set: Average loss: 1.5839, Accuracy: 317/542 (58%)\n",
      "\n",
      "Train Epoch: 62 [0/2166 (0%)]\tLoss: 1.490662\n",
      "Train Epoch: 62 [640/2166 (29%)]\tLoss: 1.542735\n",
      "Train Epoch: 62 [1280/2166 (59%)]\tLoss: 1.610980\n",
      "Train Epoch: 62 [1920/2166 (88%)]\tLoss: 1.539253\n",
      "\n",
      "Test set: Average loss: 1.5818, Accuracy: 317/542 (58%)\n",
      "\n",
      "Train Epoch: 63 [0/2166 (0%)]\tLoss: 1.531938\n",
      "Train Epoch: 63 [640/2166 (29%)]\tLoss: 1.596480\n",
      "Train Epoch: 63 [1280/2166 (59%)]\tLoss: 1.568572\n",
      "Train Epoch: 63 [1920/2166 (88%)]\tLoss: 1.499189\n",
      "\n",
      "Test set: Average loss: 1.5800, Accuracy: 318/542 (59%)\n",
      "\n",
      "Train Epoch: 64 [0/2166 (0%)]\tLoss: 1.614640\n",
      "Train Epoch: 64 [640/2166 (29%)]\tLoss: 1.495339\n",
      "Train Epoch: 64 [1280/2166 (59%)]\tLoss: 1.555895\n",
      "Train Epoch: 64 [1920/2166 (88%)]\tLoss: 1.574624\n",
      "\n",
      "Test set: Average loss: 1.5780, Accuracy: 318/542 (59%)\n",
      "\n",
      "Train Epoch: 65 [0/2166 (0%)]\tLoss: 1.503329\n",
      "Train Epoch: 65 [640/2166 (29%)]\tLoss: 1.456619\n",
      "Train Epoch: 65 [1280/2166 (59%)]\tLoss: 1.472070\n",
      "Train Epoch: 65 [1920/2166 (88%)]\tLoss: 1.592921\n",
      "\n",
      "Test set: Average loss: 1.5762, Accuracy: 318/542 (59%)\n",
      "\n",
      "Train Epoch: 66 [0/2166 (0%)]\tLoss: 1.514653\n",
      "Train Epoch: 66 [640/2166 (29%)]\tLoss: 1.531821\n",
      "Train Epoch: 66 [1280/2166 (59%)]\tLoss: 1.514794\n",
      "Train Epoch: 66 [1920/2166 (88%)]\tLoss: 1.524568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.5744, Accuracy: 318/542 (59%)\n",
      "\n",
      "Train Epoch: 67 [0/2166 (0%)]\tLoss: 1.575848\n",
      "Train Epoch: 67 [640/2166 (29%)]\tLoss: 1.583359\n",
      "Train Epoch: 67 [1280/2166 (59%)]\tLoss: 1.505091\n",
      "Train Epoch: 67 [1920/2166 (88%)]\tLoss: 1.477651\n",
      "\n",
      "Test set: Average loss: 1.5725, Accuracy: 319/542 (59%)\n",
      "\n",
      "Train Epoch: 68 [0/2166 (0%)]\tLoss: 1.494586\n",
      "Train Epoch: 68 [640/2166 (29%)]\tLoss: 1.517061\n",
      "Train Epoch: 68 [1280/2166 (59%)]\tLoss: 1.536996\n",
      "Train Epoch: 68 [1920/2166 (88%)]\tLoss: 1.481224\n",
      "\n",
      "Test set: Average loss: 1.5707, Accuracy: 319/542 (59%)\n",
      "\n",
      "Train Epoch: 69 [0/2166 (0%)]\tLoss: 1.509212\n",
      "Train Epoch: 69 [640/2166 (29%)]\tLoss: 1.522695\n",
      "Train Epoch: 69 [1280/2166 (59%)]\tLoss: 1.555849\n",
      "Train Epoch: 69 [1920/2166 (88%)]\tLoss: 1.545057\n",
      "\n",
      "Test set: Average loss: 1.5689, Accuracy: 319/542 (59%)\n",
      "\n",
      "Train Epoch: 70 [0/2166 (0%)]\tLoss: 1.534770\n",
      "Train Epoch: 70 [640/2166 (29%)]\tLoss: 1.562555\n",
      "Train Epoch: 70 [1280/2166 (59%)]\tLoss: 1.575869\n",
      "Train Epoch: 70 [1920/2166 (88%)]\tLoss: 1.504752\n",
      "\n",
      "Test set: Average loss: 1.5673, Accuracy: 319/542 (59%)\n",
      "\n",
      "Train Epoch: 71 [0/2166 (0%)]\tLoss: 1.527137\n",
      "Train Epoch: 71 [640/2166 (29%)]\tLoss: 1.619001\n",
      "Train Epoch: 71 [1280/2166 (59%)]\tLoss: 1.515029\n",
      "Train Epoch: 71 [1920/2166 (88%)]\tLoss: 1.557190\n",
      "\n",
      "Test set: Average loss: 1.5656, Accuracy: 320/542 (59%)\n",
      "\n",
      "Train Epoch: 72 [0/2166 (0%)]\tLoss: 1.552256\n",
      "Train Epoch: 72 [640/2166 (29%)]\tLoss: 1.580055\n",
      "Train Epoch: 72 [1280/2166 (59%)]\tLoss: 1.579397\n",
      "Train Epoch: 72 [1920/2166 (88%)]\tLoss: 1.514483\n",
      "\n",
      "Test set: Average loss: 1.5640, Accuracy: 320/542 (59%)\n",
      "\n",
      "Train Epoch: 73 [0/2166 (0%)]\tLoss: 1.494185\n",
      "Train Epoch: 73 [640/2166 (29%)]\tLoss: 1.528910\n",
      "Train Epoch: 73 [1280/2166 (59%)]\tLoss: 1.570913\n",
      "Train Epoch: 73 [1920/2166 (88%)]\tLoss: 1.538054\n",
      "\n",
      "Test set: Average loss: 1.5624, Accuracy: 320/542 (59%)\n",
      "\n",
      "Train Epoch: 74 [0/2166 (0%)]\tLoss: 1.498145\n",
      "Train Epoch: 74 [640/2166 (29%)]\tLoss: 1.553894\n",
      "Train Epoch: 74 [1280/2166 (59%)]\tLoss: 1.545541\n",
      "Train Epoch: 74 [1920/2166 (88%)]\tLoss: 1.640903\n",
      "\n",
      "Test set: Average loss: 1.5608, Accuracy: 321/542 (59%)\n",
      "\n",
      "Train Epoch: 75 [0/2166 (0%)]\tLoss: 1.536401\n",
      "Train Epoch: 75 [640/2166 (29%)]\tLoss: 1.494553\n",
      "Train Epoch: 75 [1280/2166 (59%)]\tLoss: 1.520890\n",
      "Train Epoch: 75 [1920/2166 (88%)]\tLoss: 1.511428\n",
      "\n",
      "Test set: Average loss: 1.5593, Accuracy: 321/542 (59%)\n",
      "\n",
      "Train Epoch: 76 [0/2166 (0%)]\tLoss: 1.456527\n",
      "Train Epoch: 76 [640/2166 (29%)]\tLoss: 1.494712\n",
      "Train Epoch: 76 [1280/2166 (59%)]\tLoss: 1.519084\n",
      "Train Epoch: 76 [1920/2166 (88%)]\tLoss: 1.594411\n",
      "\n",
      "Test set: Average loss: 1.5578, Accuracy: 322/542 (59%)\n",
      "\n",
      "Train Epoch: 77 [0/2166 (0%)]\tLoss: 1.546807\n",
      "Train Epoch: 77 [640/2166 (29%)]\tLoss: 1.515303\n",
      "Train Epoch: 77 [1280/2166 (59%)]\tLoss: 1.503677\n",
      "Train Epoch: 77 [1920/2166 (88%)]\tLoss: 1.538473\n",
      "\n",
      "Test set: Average loss: 1.5564, Accuracy: 323/542 (60%)\n",
      "\n",
      "Train Epoch: 78 [0/2166 (0%)]\tLoss: 1.488509\n",
      "Train Epoch: 78 [640/2166 (29%)]\tLoss: 1.562544\n",
      "Train Epoch: 78 [1280/2166 (59%)]\tLoss: 1.544993\n",
      "Train Epoch: 78 [1920/2166 (88%)]\tLoss: 1.488485\n",
      "\n",
      "Test set: Average loss: 1.5549, Accuracy: 324/542 (60%)\n",
      "\n",
      "Train Epoch: 79 [0/2166 (0%)]\tLoss: 1.554355\n",
      "Train Epoch: 79 [640/2166 (29%)]\tLoss: 1.556495\n",
      "Train Epoch: 79 [1280/2166 (59%)]\tLoss: 1.497496\n",
      "Train Epoch: 79 [1920/2166 (88%)]\tLoss: 1.541864\n",
      "\n",
      "Test set: Average loss: 1.5535, Accuracy: 325/542 (60%)\n",
      "\n",
      "Train Epoch: 80 [0/2166 (0%)]\tLoss: 1.498668\n",
      "Train Epoch: 80 [640/2166 (29%)]\tLoss: 1.491605\n",
      "Train Epoch: 80 [1280/2166 (59%)]\tLoss: 1.496956\n",
      "Train Epoch: 80 [1920/2166 (88%)]\tLoss: 1.573047\n",
      "\n",
      "Test set: Average loss: 1.5520, Accuracy: 326/542 (60%)\n",
      "\n",
      "Train Epoch: 81 [0/2166 (0%)]\tLoss: 1.567848\n",
      "Train Epoch: 81 [640/2166 (29%)]\tLoss: 1.504776\n",
      "Train Epoch: 81 [1280/2166 (59%)]\tLoss: 1.504474\n",
      "Train Epoch: 81 [1920/2166 (88%)]\tLoss: 1.575346\n",
      "\n",
      "Test set: Average loss: 1.5508, Accuracy: 325/542 (60%)\n",
      "\n",
      "Train Epoch: 82 [0/2166 (0%)]\tLoss: 1.417893\n",
      "Train Epoch: 82 [640/2166 (29%)]\tLoss: 1.494711\n",
      "Train Epoch: 82 [1280/2166 (59%)]\tLoss: 1.480581\n",
      "Train Epoch: 82 [1920/2166 (88%)]\tLoss: 1.536521\n",
      "\n",
      "Test set: Average loss: 1.5493, Accuracy: 325/542 (60%)\n",
      "\n",
      "Train Epoch: 83 [0/2166 (0%)]\tLoss: 1.492031\n",
      "Train Epoch: 83 [640/2166 (29%)]\tLoss: 1.449673\n",
      "Train Epoch: 83 [1280/2166 (59%)]\tLoss: 1.572879\n",
      "Train Epoch: 83 [1920/2166 (88%)]\tLoss: 1.520933\n",
      "\n",
      "Test set: Average loss: 1.5481, Accuracy: 327/542 (60%)\n",
      "\n",
      "Train Epoch: 84 [0/2166 (0%)]\tLoss: 1.500560\n",
      "Train Epoch: 84 [640/2166 (29%)]\tLoss: 1.467612\n",
      "Train Epoch: 84 [1280/2166 (59%)]\tLoss: 1.545699\n",
      "Train Epoch: 84 [1920/2166 (88%)]\tLoss: 1.456036\n",
      "\n",
      "Test set: Average loss: 1.5469, Accuracy: 327/542 (60%)\n",
      "\n",
      "Train Epoch: 85 [0/2166 (0%)]\tLoss: 1.450338\n",
      "Train Epoch: 85 [640/2166 (29%)]\tLoss: 1.586815\n",
      "Train Epoch: 85 [1280/2166 (59%)]\tLoss: 1.477652\n",
      "Train Epoch: 85 [1920/2166 (88%)]\tLoss: 1.537534\n",
      "\n",
      "Test set: Average loss: 1.5456, Accuracy: 327/542 (60%)\n",
      "\n",
      "Train Epoch: 86 [0/2166 (0%)]\tLoss: 1.479751\n",
      "Train Epoch: 86 [640/2166 (29%)]\tLoss: 1.498521\n",
      "Train Epoch: 86 [1280/2166 (59%)]\tLoss: 1.512119\n",
      "Train Epoch: 86 [1920/2166 (88%)]\tLoss: 1.574148\n",
      "\n",
      "Test set: Average loss: 1.5444, Accuracy: 327/542 (60%)\n",
      "\n",
      "Train Epoch: 87 [0/2166 (0%)]\tLoss: 1.508088\n",
      "Train Epoch: 87 [640/2166 (29%)]\tLoss: 1.491988\n",
      "Train Epoch: 87 [1280/2166 (59%)]\tLoss: 1.441793\n",
      "Train Epoch: 87 [1920/2166 (88%)]\tLoss: 1.521710\n",
      "\n",
      "Test set: Average loss: 1.5432, Accuracy: 330/542 (61%)\n",
      "\n",
      "Train Epoch: 88 [0/2166 (0%)]\tLoss: 1.470170\n",
      "Train Epoch: 88 [640/2166 (29%)]\tLoss: 1.572501\n",
      "Train Epoch: 88 [1280/2166 (59%)]\tLoss: 1.548592\n",
      "Train Epoch: 88 [1920/2166 (88%)]\tLoss: 1.495303\n",
      "\n",
      "Test set: Average loss: 1.5420, Accuracy: 330/542 (61%)\n",
      "\n",
      "Train Epoch: 89 [0/2166 (0%)]\tLoss: 1.514906\n",
      "Train Epoch: 89 [640/2166 (29%)]\tLoss: 1.511458\n",
      "Train Epoch: 89 [1280/2166 (59%)]\tLoss: 1.468675\n",
      "Train Epoch: 89 [1920/2166 (88%)]\tLoss: 1.567380\n",
      "\n",
      "Test set: Average loss: 1.5408, Accuracy: 329/542 (61%)\n",
      "\n",
      "Train Epoch: 90 [0/2166 (0%)]\tLoss: 1.569198\n",
      "Train Epoch: 90 [640/2166 (29%)]\tLoss: 1.547549\n",
      "Train Epoch: 90 [1280/2166 (59%)]\tLoss: 1.513075\n",
      "Train Epoch: 90 [1920/2166 (88%)]\tLoss: 1.451442\n",
      "\n",
      "Test set: Average loss: 1.5396, Accuracy: 330/542 (61%)\n",
      "\n",
      "Train Epoch: 91 [0/2166 (0%)]\tLoss: 1.596169\n",
      "Train Epoch: 91 [640/2166 (29%)]\tLoss: 1.453313\n",
      "Train Epoch: 91 [1280/2166 (59%)]\tLoss: 1.478623\n",
      "Train Epoch: 91 [1920/2166 (88%)]\tLoss: 1.603343\n",
      "\n",
      "Test set: Average loss: 1.5386, Accuracy: 332/542 (61%)\n",
      "\n",
      "Train Epoch: 92 [0/2166 (0%)]\tLoss: 1.516897\n",
      "Train Epoch: 92 [640/2166 (29%)]\tLoss: 1.482340\n",
      "Train Epoch: 92 [1280/2166 (59%)]\tLoss: 1.521444\n",
      "Train Epoch: 92 [1920/2166 (88%)]\tLoss: 1.508369\n",
      "\n",
      "Test set: Average loss: 1.5374, Accuracy: 332/542 (61%)\n",
      "\n",
      "Train Epoch: 93 [0/2166 (0%)]\tLoss: 1.501590\n",
      "Train Epoch: 93 [640/2166 (29%)]\tLoss: 1.478268\n",
      "Train Epoch: 93 [1280/2166 (59%)]\tLoss: 1.527041\n",
      "Train Epoch: 93 [1920/2166 (88%)]\tLoss: 1.561224\n",
      "\n",
      "Test set: Average loss: 1.5363, Accuracy: 332/542 (61%)\n",
      "\n",
      "Train Epoch: 94 [0/2166 (0%)]\tLoss: 1.522625\n",
      "Train Epoch: 94 [640/2166 (29%)]\tLoss: 1.518390\n",
      "Train Epoch: 94 [1280/2166 (59%)]\tLoss: 1.496780\n",
      "Train Epoch: 94 [1920/2166 (88%)]\tLoss: 1.522718\n",
      "\n",
      "Test set: Average loss: 1.5353, Accuracy: 332/542 (61%)\n",
      "\n",
      "Train Epoch: 95 [0/2166 (0%)]\tLoss: 1.435720\n",
      "Train Epoch: 95 [640/2166 (29%)]\tLoss: 1.507650\n",
      "Train Epoch: 95 [1280/2166 (59%)]\tLoss: 1.437944\n",
      "Train Epoch: 95 [1920/2166 (88%)]\tLoss: 1.547668\n",
      "\n",
      "Test set: Average loss: 1.5343, Accuracy: 332/542 (61%)\n",
      "\n",
      "Train Epoch: 96 [0/2166 (0%)]\tLoss: 1.496525\n",
      "Train Epoch: 96 [640/2166 (29%)]\tLoss: 1.526460\n",
      "Train Epoch: 96 [1280/2166 (59%)]\tLoss: 1.446984\n",
      "Train Epoch: 96 [1920/2166 (88%)]\tLoss: 1.486919\n",
      "\n",
      "Test set: Average loss: 1.5332, Accuracy: 332/542 (61%)\n",
      "\n",
      "Train Epoch: 97 [0/2166 (0%)]\tLoss: 1.459115\n",
      "Train Epoch: 97 [640/2166 (29%)]\tLoss: 1.487555\n",
      "Train Epoch: 97 [1280/2166 (59%)]\tLoss: 1.508191\n",
      "Train Epoch: 97 [1920/2166 (88%)]\tLoss: 1.527099\n",
      "\n",
      "Test set: Average loss: 1.5321, Accuracy: 332/542 (61%)\n",
      "\n",
      "Train Epoch: 98 [0/2166 (0%)]\tLoss: 1.513390\n",
      "Train Epoch: 98 [640/2166 (29%)]\tLoss: 1.495324\n",
      "Train Epoch: 98 [1280/2166 (59%)]\tLoss: 1.461706\n",
      "Train Epoch: 98 [1920/2166 (88%)]\tLoss: 1.577055\n",
      "\n",
      "Test set: Average loss: 1.5311, Accuracy: 332/542 (61%)\n",
      "\n",
      "Train Epoch: 99 [0/2166 (0%)]\tLoss: 1.502030\n",
      "Train Epoch: 99 [640/2166 (29%)]\tLoss: 1.523618\n",
      "Train Epoch: 99 [1280/2166 (59%)]\tLoss: 1.544089\n",
      "Train Epoch: 99 [1920/2166 (88%)]\tLoss: 1.516622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.5302, Accuracy: 333/542 (61%)\n",
      "\n",
      "Train Epoch: 100 [0/2166 (0%)]\tLoss: 1.457274\n",
      "Train Epoch: 100 [640/2166 (29%)]\tLoss: 1.513364\n",
      "Train Epoch: 100 [1280/2166 (59%)]\tLoss: 1.533000\n",
      "Train Epoch: 100 [1920/2166 (88%)]\tLoss: 1.421636\n",
      "\n",
      "Test set: Average loss: 1.5293, Accuracy: 332/542 (61%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = FNet()\n",
    "FNet_test_acc = []\n",
    "FNet_train_acc = []\n",
    "device = torch.device('cuda')\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "cora_train_dataloader = DataLoader(cora_train_dataset, batch_size=64, shuffle=True, **kwargs)\n",
    "cora_test_dataloader = DataLoader(cora_test_dataset, batch_size=1000, shuffle=True, **kwargs)\n",
    "model.to(device)\n",
    "print(model)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-1)\n",
    "print('number of trainable parameters: %d' %\n",
    "          np.sum([np.prod(p.size()) if p.requires_grad else 0 for p in model.parameters()]))\n",
    "for epoch in range(1, 101):\n",
    "    train(model, device, cora_train_dataloader, optimizer, epoch)\n",
    "    accs = test(model, device, cora_test_dataloader, cora_train_dataloader)\n",
    "    FNet_test_acc.append(accs[0])\n",
    "    FNet_train_acc.append(accs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(1, 101), FNet_test_acc, label = \"test_acc\")\n",
    "plt.plot(range(1, 101), FNet_train_acc, label = \"train_acc\")\n",
    "plt.legend()\n",
    "plt.title(\"full connected network on cora dataset accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class one_layer_GraphNet(nn.Module):\n",
    "    def __init__(self, A, X, pred_edge=False):\n",
    "        super(one_layer_GraphNet, self).__init__()\n",
    "        self.pred_edge = pred_edge\n",
    "        N = 1433\n",
    "        self.fc = nn.Linear(N, 7, bias=False)\n",
    "        # precompute adjacency matrix before training\n",
    "        self.A = A\n",
    "        self.register_buffer('X', X.float())\n",
    "\n",
    "    def forward(self, x, batch_idx, batch_size=64):\n",
    "        B = x.size(0)\n",
    "        # average all neighboors\n",
    "        #print(x.shape)\n",
    "        A = torch.from_numpy(self.A[batch_idx*batch_size:batch_idx*batch_size+64]).float()\n",
    "        A = A.float()\n",
    "        A = A.to(device)\n",
    "        #print(A.shape)\n",
    "        #print(self.X.shape)\n",
    "        #print(A.dtype, self.X.dtype, x.dtype)\n",
    "        avg_neighbor_features = torch.matmul(A, self.X)\n",
    "        x = x.float()\n",
    "        return self.fc(avg_neighbor_features)\n",
    "    \n",
    "def train(model, device, train_loader, optimizer):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data, batch_idx)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data, batch_idx)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(\n",
    "    '\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return 100. * correct / len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2708"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n",
      "    close()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "\n"
     ]
    }
   ],
   "source": [
    "G = nx.read_edgelist(\"cora.cites\") #read\n",
    "display(G.number_of_nodes())\n",
    "\n",
    "# calculate the adjance matrix and normalize it\n",
    "A = nx.adjacency_matrix(G).todense()\n",
    "#A = torch.from_numpy(A).float()\n",
    "A = np.asarray(A).reshape(2708, 2708)\n",
    "\n",
    "X = features[:, 1: -1].astype(int)\n",
    "X = torch.from_numpy(X).type(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNet(\n",
      "  (fc): Linear(in_features=1433, out_features=7, bias=False)\n",
      ")\n",
      "number of trainable parameters: 10031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/2708 (0%)]\tLoss: 1.931578\n",
      "Train Epoch: 1 [640/2708 (23%)]\tLoss: 1.997056\n",
      "Train Epoch: 1 [1280/2708 (47%)]\tLoss: 1.939596\n",
      "Train Epoch: 1 [1920/2708 (70%)]\tLoss: 1.980574\n",
      "Train Epoch: 1 [2560/2708 (93%)]\tLoss: 1.979667\n",
      "\n",
      "Test set: Average loss: 1.9655, Accuracy: 334/2708 (12%)\n",
      "\n",
      "Train Epoch: 2 [0/2708 (0%)]\tLoss: 2.048614\n",
      "Train Epoch: 2 [640/2708 (23%)]\tLoss: 1.961201\n",
      "Train Epoch: 2 [1280/2708 (47%)]\tLoss: 1.997558\n",
      "Train Epoch: 2 [1920/2708 (70%)]\tLoss: 1.980626\n",
      "Train Epoch: 2 [2560/2708 (93%)]\tLoss: 1.973686\n",
      "\n",
      "Test set: Average loss: 1.9728, Accuracy: 306/2708 (11%)\n",
      "\n",
      "Train Epoch: 3 [0/2708 (0%)]\tLoss: 1.959840\n",
      "Train Epoch: 3 [640/2708 (23%)]\tLoss: 1.931158\n",
      "Train Epoch: 3 [1280/2708 (47%)]\tLoss: 2.000509\n",
      "Train Epoch: 3 [1920/2708 (70%)]\tLoss: 1.973112\n",
      "Train Epoch: 3 [2560/2708 (93%)]\tLoss: 1.971459\n",
      "\n",
      "Test set: Average loss: 1.9710, Accuracy: 324/2708 (12%)\n",
      "\n",
      "Train Epoch: 4 [0/2708 (0%)]\tLoss: 1.991351\n",
      "Train Epoch: 4 [640/2708 (23%)]\tLoss: 1.978229\n",
      "Train Epoch: 4 [1280/2708 (47%)]\tLoss: 1.966088\n",
      "Train Epoch: 4 [1920/2708 (70%)]\tLoss: 1.958340\n",
      "Train Epoch: 4 [2560/2708 (93%)]\tLoss: 1.967530\n",
      "\n",
      "Test set: Average loss: 1.9721, Accuracy: 351/2708 (13%)\n",
      "\n",
      "Train Epoch: 5 [0/2708 (0%)]\tLoss: 2.016994\n",
      "Train Epoch: 5 [640/2708 (23%)]\tLoss: 1.993863\n",
      "Train Epoch: 5 [1280/2708 (47%)]\tLoss: 1.957237\n",
      "Train Epoch: 5 [1920/2708 (70%)]\tLoss: 1.977456\n",
      "Train Epoch: 5 [2560/2708 (93%)]\tLoss: 1.950183\n",
      "\n",
      "Test set: Average loss: 1.9714, Accuracy: 322/2708 (12%)\n",
      "\n",
      "Train Epoch: 6 [0/2708 (0%)]\tLoss: 1.948222\n",
      "Train Epoch: 6 [640/2708 (23%)]\tLoss: 1.969992\n",
      "Train Epoch: 6 [1280/2708 (47%)]\tLoss: 1.973207\n",
      "Train Epoch: 6 [1920/2708 (70%)]\tLoss: 1.954354\n",
      "Train Epoch: 6 [2560/2708 (93%)]\tLoss: 1.960019\n",
      "\n",
      "Test set: Average loss: 1.9691, Accuracy: 339/2708 (13%)\n",
      "\n",
      "Train Epoch: 7 [0/2708 (0%)]\tLoss: 2.049345\n",
      "Train Epoch: 7 [640/2708 (23%)]\tLoss: 1.997555\n",
      "Train Epoch: 7 [1280/2708 (47%)]\tLoss: 1.962906\n",
      "Train Epoch: 7 [1920/2708 (70%)]\tLoss: 1.973556\n",
      "Train Epoch: 7 [2560/2708 (93%)]\tLoss: 1.944404\n",
      "\n",
      "Test set: Average loss: 1.9712, Accuracy: 356/2708 (13%)\n",
      "\n",
      "Train Epoch: 8 [0/2708 (0%)]\tLoss: 2.031245\n",
      "Train Epoch: 8 [640/2708 (23%)]\tLoss: 1.973191\n",
      "Train Epoch: 8 [1280/2708 (47%)]\tLoss: 2.004066\n",
      "Train Epoch: 8 [1920/2708 (70%)]\tLoss: 1.930979\n",
      "Train Epoch: 8 [2560/2708 (93%)]\tLoss: 1.953421\n",
      "\n",
      "Test set: Average loss: 1.9715, Accuracy: 319/2708 (12%)\n",
      "\n",
      "Train Epoch: 9 [0/2708 (0%)]\tLoss: 1.999644\n",
      "Train Epoch: 9 [640/2708 (23%)]\tLoss: 1.989869\n",
      "Train Epoch: 9 [1280/2708 (47%)]\tLoss: 1.980388\n",
      "Train Epoch: 9 [1920/2708 (70%)]\tLoss: 1.967508\n",
      "Train Epoch: 9 [2560/2708 (93%)]\tLoss: 1.967695\n",
      "\n",
      "Test set: Average loss: 1.9688, Accuracy: 299/2708 (11%)\n",
      "\n",
      "Train Epoch: 10 [0/2708 (0%)]\tLoss: 2.008039\n",
      "Train Epoch: 10 [640/2708 (23%)]\tLoss: 1.988596\n",
      "Train Epoch: 10 [1280/2708 (47%)]\tLoss: 1.975320\n",
      "Train Epoch: 10 [1920/2708 (70%)]\tLoss: 1.956766\n",
      "Train Epoch: 10 [2560/2708 (93%)]\tLoss: 1.960717\n",
      "\n",
      "Test set: Average loss: 1.9735, Accuracy: 337/2708 (12%)\n",
      "\n",
      "Train Epoch: 11 [0/2708 (0%)]\tLoss: 2.010470\n",
      "Train Epoch: 11 [640/2708 (23%)]\tLoss: 1.950051\n",
      "Train Epoch: 11 [1280/2708 (47%)]\tLoss: 1.994543\n",
      "Train Epoch: 11 [1920/2708 (70%)]\tLoss: 1.965523\n",
      "Train Epoch: 11 [2560/2708 (93%)]\tLoss: 1.953010\n",
      "\n",
      "Test set: Average loss: 1.9705, Accuracy: 315/2708 (12%)\n",
      "\n",
      "Train Epoch: 12 [0/2708 (0%)]\tLoss: 2.002185\n",
      "Train Epoch: 12 [640/2708 (23%)]\tLoss: 1.975137\n",
      "Train Epoch: 12 [1280/2708 (47%)]\tLoss: 1.981313\n",
      "Train Epoch: 12 [1920/2708 (70%)]\tLoss: 1.967546\n",
      "Train Epoch: 12 [2560/2708 (93%)]\tLoss: 1.967670\n",
      "\n",
      "Test set: Average loss: 1.9686, Accuracy: 349/2708 (13%)\n",
      "\n",
      "Train Epoch: 13 [0/2708 (0%)]\tLoss: 1.998374\n",
      "Train Epoch: 13 [640/2708 (23%)]\tLoss: 1.967063\n",
      "Train Epoch: 13 [1280/2708 (47%)]\tLoss: 1.999007\n",
      "Train Epoch: 13 [1920/2708 (70%)]\tLoss: 1.979676\n",
      "Train Epoch: 13 [2560/2708 (93%)]\tLoss: 1.977569\n",
      "\n",
      "Test set: Average loss: 1.9676, Accuracy: 329/2708 (12%)\n",
      "\n",
      "Train Epoch: 14 [0/2708 (0%)]\tLoss: 1.951964\n",
      "Train Epoch: 14 [640/2708 (23%)]\tLoss: 1.992247\n",
      "Train Epoch: 14 [1280/2708 (47%)]\tLoss: 2.005778\n",
      "Train Epoch: 14 [1920/2708 (70%)]\tLoss: 1.952704\n",
      "Train Epoch: 14 [2560/2708 (93%)]\tLoss: 1.955954\n",
      "\n",
      "Test set: Average loss: 1.9726, Accuracy: 315/2708 (12%)\n",
      "\n",
      "Train Epoch: 15 [0/2708 (0%)]\tLoss: 1.999613\n",
      "Train Epoch: 15 [640/2708 (23%)]\tLoss: 1.968818\n",
      "Train Epoch: 15 [1280/2708 (47%)]\tLoss: 1.977311\n",
      "Train Epoch: 15 [1920/2708 (70%)]\tLoss: 1.976858\n",
      "Train Epoch: 15 [2560/2708 (93%)]\tLoss: 1.963886\n",
      "\n",
      "Test set: Average loss: 1.9746, Accuracy: 317/2708 (12%)\n",
      "\n",
      "Train Epoch: 16 [0/2708 (0%)]\tLoss: 2.008222\n",
      "Train Epoch: 16 [640/2708 (23%)]\tLoss: 1.953997\n",
      "Train Epoch: 16 [1280/2708 (47%)]\tLoss: 1.986789\n",
      "Train Epoch: 16 [1920/2708 (70%)]\tLoss: 1.954618\n",
      "Train Epoch: 16 [2560/2708 (93%)]\tLoss: 1.954197\n",
      "\n",
      "Test set: Average loss: 1.9722, Accuracy: 327/2708 (12%)\n",
      "\n",
      "Train Epoch: 17 [0/2708 (0%)]\tLoss: 2.020380\n",
      "Train Epoch: 17 [640/2708 (23%)]\tLoss: 1.938348\n",
      "Train Epoch: 17 [1280/2708 (47%)]\tLoss: 1.964651\n",
      "Train Epoch: 17 [1920/2708 (70%)]\tLoss: 1.961051\n",
      "Train Epoch: 17 [2560/2708 (93%)]\tLoss: 1.975639\n",
      "\n",
      "Test set: Average loss: 1.9687, Accuracy: 348/2708 (13%)\n",
      "\n",
      "Train Epoch: 18 [0/2708 (0%)]\tLoss: 2.048092\n",
      "Train Epoch: 18 [640/2708 (23%)]\tLoss: 1.970520\n",
      "Train Epoch: 18 [1280/2708 (47%)]\tLoss: 2.008737\n",
      "Train Epoch: 18 [1920/2708 (70%)]\tLoss: 1.972404\n",
      "Train Epoch: 18 [2560/2708 (93%)]\tLoss: 1.989515\n",
      "\n",
      "Test set: Average loss: 1.9744, Accuracy: 304/2708 (11%)\n",
      "\n",
      "Train Epoch: 19 [0/2708 (0%)]\tLoss: 1.943122\n",
      "Train Epoch: 19 [640/2708 (23%)]\tLoss: 1.986834\n",
      "Train Epoch: 19 [1280/2708 (47%)]\tLoss: 1.981088\n",
      "Train Epoch: 19 [1920/2708 (70%)]\tLoss: 1.972805\n",
      "Train Epoch: 19 [2560/2708 (93%)]\tLoss: 1.986855\n",
      "\n",
      "Test set: Average loss: 1.9660, Accuracy: 339/2708 (13%)\n",
      "\n",
      "Train Epoch: 20 [0/2708 (0%)]\tLoss: 2.022946\n",
      "Train Epoch: 20 [640/2708 (23%)]\tLoss: 1.974391\n",
      "Train Epoch: 20 [1280/2708 (47%)]\tLoss: 1.986064\n",
      "Train Epoch: 20 [1920/2708 (70%)]\tLoss: 1.969119\n",
      "Train Epoch: 20 [2560/2708 (93%)]\tLoss: 1.933585\n",
      "\n",
      "Test set: Average loss: 1.9745, Accuracy: 320/2708 (12%)\n",
      "\n",
      "Train Epoch: 21 [0/2708 (0%)]\tLoss: 2.010171\n",
      "Train Epoch: 21 [640/2708 (23%)]\tLoss: 1.985712\n",
      "Train Epoch: 21 [1280/2708 (47%)]\tLoss: 1.976688\n",
      "Train Epoch: 21 [1920/2708 (70%)]\tLoss: 1.955047\n",
      "Train Epoch: 21 [2560/2708 (93%)]\tLoss: 1.968808\n",
      "\n",
      "Test set: Average loss: 1.9725, Accuracy: 329/2708 (12%)\n",
      "\n",
      "Train Epoch: 22 [0/2708 (0%)]\tLoss: 2.084291\n",
      "Train Epoch: 22 [640/2708 (23%)]\tLoss: 1.982066\n",
      "Train Epoch: 22 [1280/2708 (47%)]\tLoss: 1.986678\n",
      "Train Epoch: 22 [1920/2708 (70%)]\tLoss: 1.949192\n",
      "Train Epoch: 22 [2560/2708 (93%)]\tLoss: 1.972738\n",
      "\n",
      "Test set: Average loss: 1.9729, Accuracy: 307/2708 (11%)\n",
      "\n",
      "Train Epoch: 23 [0/2708 (0%)]\tLoss: 2.044209\n",
      "Train Epoch: 23 [640/2708 (23%)]\tLoss: 1.957889\n",
      "Train Epoch: 23 [1280/2708 (47%)]\tLoss: 1.993746\n",
      "Train Epoch: 23 [1920/2708 (70%)]\tLoss: 1.975013\n",
      "Train Epoch: 23 [2560/2708 (93%)]\tLoss: 1.954083\n",
      "\n",
      "Test set: Average loss: 1.9682, Accuracy: 329/2708 (12%)\n",
      "\n",
      "Train Epoch: 24 [0/2708 (0%)]\tLoss: 1.939829\n",
      "Train Epoch: 24 [640/2708 (23%)]\tLoss: 1.989849\n",
      "Train Epoch: 24 [1280/2708 (47%)]\tLoss: 1.959521\n",
      "Train Epoch: 24 [1920/2708 (70%)]\tLoss: 1.995105\n",
      "Train Epoch: 24 [2560/2708 (93%)]\tLoss: 1.969201\n",
      "\n",
      "Test set: Average loss: 1.9724, Accuracy: 338/2708 (12%)\n",
      "\n",
      "Train Epoch: 25 [0/2708 (0%)]\tLoss: 2.033872\n",
      "Train Epoch: 25 [640/2708 (23%)]\tLoss: 1.948279\n",
      "Train Epoch: 25 [1280/2708 (47%)]\tLoss: 1.961462\n",
      "Train Epoch: 25 [1920/2708 (70%)]\tLoss: 1.960461\n",
      "Train Epoch: 25 [2560/2708 (93%)]\tLoss: 1.957522\n",
      "\n",
      "Test set: Average loss: 1.9725, Accuracy: 336/2708 (12%)\n",
      "\n",
      "Train Epoch: 26 [0/2708 (0%)]\tLoss: 2.070957\n",
      "Train Epoch: 26 [640/2708 (23%)]\tLoss: 1.991465\n",
      "Train Epoch: 26 [1280/2708 (47%)]\tLoss: 1.982667\n",
      "Train Epoch: 26 [1920/2708 (70%)]\tLoss: 1.983499\n",
      "Train Epoch: 26 [2560/2708 (93%)]\tLoss: 1.970461\n",
      "\n",
      "Test set: Average loss: 1.9694, Accuracy: 317/2708 (12%)\n",
      "\n",
      "Train Epoch: 27 [0/2708 (0%)]\tLoss: 2.036630\n",
      "Train Epoch: 27 [640/2708 (23%)]\tLoss: 1.958500\n",
      "Train Epoch: 27 [1280/2708 (47%)]\tLoss: 1.974690\n",
      "Train Epoch: 27 [1920/2708 (70%)]\tLoss: 1.960855\n",
      "Train Epoch: 27 [2560/2708 (93%)]\tLoss: 1.963558\n",
      "\n",
      "Test set: Average loss: 1.9700, Accuracy: 321/2708 (12%)\n",
      "\n",
      "Train Epoch: 28 [0/2708 (0%)]\tLoss: 1.949461\n",
      "Train Epoch: 28 [640/2708 (23%)]\tLoss: 1.943986\n",
      "Train Epoch: 28 [1280/2708 (47%)]\tLoss: 1.976861\n",
      "Train Epoch: 28 [1920/2708 (70%)]\tLoss: 1.951106\n",
      "Train Epoch: 28 [2560/2708 (93%)]\tLoss: 1.962687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.9743, Accuracy: 323/2708 (12%)\n",
      "\n",
      "Train Epoch: 29 [0/2708 (0%)]\tLoss: 2.012794\n",
      "Train Epoch: 29 [640/2708 (23%)]\tLoss: 1.968732\n",
      "Train Epoch: 29 [1280/2708 (47%)]\tLoss: 1.970714\n",
      "Train Epoch: 29 [1920/2708 (70%)]\tLoss: 1.962744\n",
      "Train Epoch: 29 [2560/2708 (93%)]\tLoss: 1.979801\n",
      "\n",
      "Test set: Average loss: 1.9722, Accuracy: 343/2708 (13%)\n",
      "\n",
      "Train Epoch: 30 [0/2708 (0%)]\tLoss: 2.090175\n",
      "Train Epoch: 30 [640/2708 (23%)]\tLoss: 1.960992\n",
      "Train Epoch: 30 [1280/2708 (47%)]\tLoss: 1.997814\n",
      "Train Epoch: 30 [1920/2708 (70%)]\tLoss: 1.948100\n",
      "Train Epoch: 30 [2560/2708 (93%)]\tLoss: 1.957120\n",
      "\n",
      "Test set: Average loss: 1.9747, Accuracy: 304/2708 (11%)\n",
      "\n",
      "Train Epoch: 31 [0/2708 (0%)]\tLoss: 2.027785\n",
      "Train Epoch: 31 [640/2708 (23%)]\tLoss: 1.977527\n",
      "Train Epoch: 31 [1280/2708 (47%)]\tLoss: 1.945505\n",
      "Train Epoch: 31 [1920/2708 (70%)]\tLoss: 1.980674\n",
      "Train Epoch: 31 [2560/2708 (93%)]\tLoss: 1.958087\n",
      "\n",
      "Test set: Average loss: 1.9761, Accuracy: 334/2708 (12%)\n",
      "\n",
      "Train Epoch: 32 [0/2708 (0%)]\tLoss: 2.002501\n",
      "Train Epoch: 32 [640/2708 (23%)]\tLoss: 1.964928\n",
      "Train Epoch: 32 [1280/2708 (47%)]\tLoss: 1.984306\n",
      "Train Epoch: 32 [1920/2708 (70%)]\tLoss: 1.976834\n",
      "Train Epoch: 32 [2560/2708 (93%)]\tLoss: 1.966251\n",
      "\n",
      "Test set: Average loss: 1.9697, Accuracy: 365/2708 (13%)\n",
      "\n",
      "Train Epoch: 33 [0/2708 (0%)]\tLoss: 2.086120\n",
      "Train Epoch: 33 [640/2708 (23%)]\tLoss: 1.960762\n",
      "Train Epoch: 33 [1280/2708 (47%)]\tLoss: 1.969860\n",
      "Train Epoch: 33 [1920/2708 (70%)]\tLoss: 1.934811\n",
      "Train Epoch: 33 [2560/2708 (93%)]\tLoss: 1.940605\n",
      "\n",
      "Test set: Average loss: 1.9754, Accuracy: 313/2708 (12%)\n",
      "\n",
      "Train Epoch: 34 [0/2708 (0%)]\tLoss: 2.008165\n",
      "Train Epoch: 34 [640/2708 (23%)]\tLoss: 1.943229\n",
      "Train Epoch: 34 [1280/2708 (47%)]\tLoss: 1.994875\n",
      "Train Epoch: 34 [1920/2708 (70%)]\tLoss: 1.989942\n",
      "Train Epoch: 34 [2560/2708 (93%)]\tLoss: 1.944106\n",
      "\n",
      "Test set: Average loss: 1.9641, Accuracy: 335/2708 (12%)\n",
      "\n",
      "Train Epoch: 35 [0/2708 (0%)]\tLoss: 2.014157\n",
      "Train Epoch: 35 [640/2708 (23%)]\tLoss: 1.992903\n",
      "Train Epoch: 35 [1280/2708 (47%)]\tLoss: 1.982718\n",
      "Train Epoch: 35 [1920/2708 (70%)]\tLoss: 1.983187\n",
      "Train Epoch: 35 [2560/2708 (93%)]\tLoss: 1.971851\n",
      "\n",
      "Test set: Average loss: 1.9728, Accuracy: 323/2708 (12%)\n",
      "\n",
      "Train Epoch: 36 [0/2708 (0%)]\tLoss: 2.029215\n",
      "Train Epoch: 36 [640/2708 (23%)]\tLoss: 1.992923\n",
      "Train Epoch: 36 [1280/2708 (47%)]\tLoss: 1.974752\n",
      "Train Epoch: 36 [1920/2708 (70%)]\tLoss: 1.961515\n",
      "Train Epoch: 36 [2560/2708 (93%)]\tLoss: 1.948389\n",
      "\n",
      "Test set: Average loss: 1.9718, Accuracy: 336/2708 (12%)\n",
      "\n",
      "Train Epoch: 37 [0/2708 (0%)]\tLoss: 2.016866\n",
      "Train Epoch: 37 [640/2708 (23%)]\tLoss: 1.970169\n",
      "Train Epoch: 37 [1280/2708 (47%)]\tLoss: 1.981455\n",
      "Train Epoch: 37 [1920/2708 (70%)]\tLoss: 1.962340\n",
      "Train Epoch: 37 [2560/2708 (93%)]\tLoss: 1.952960\n",
      "\n",
      "Test set: Average loss: 1.9737, Accuracy: 319/2708 (12%)\n",
      "\n",
      "Train Epoch: 38 [0/2708 (0%)]\tLoss: 2.043446\n",
      "Train Epoch: 38 [640/2708 (23%)]\tLoss: 1.948841\n",
      "Train Epoch: 38 [1280/2708 (47%)]\tLoss: 1.980676\n",
      "Train Epoch: 38 [1920/2708 (70%)]\tLoss: 1.979504\n",
      "Train Epoch: 38 [2560/2708 (93%)]\tLoss: 1.958117\n",
      "\n",
      "Test set: Average loss: 1.9702, Accuracy: 352/2708 (13%)\n",
      "\n",
      "Train Epoch: 39 [0/2708 (0%)]\tLoss: 2.020538\n",
      "Train Epoch: 39 [640/2708 (23%)]\tLoss: 1.977325\n",
      "Train Epoch: 39 [1280/2708 (47%)]\tLoss: 2.001437\n",
      "Train Epoch: 39 [1920/2708 (70%)]\tLoss: 1.975928\n",
      "Train Epoch: 39 [2560/2708 (93%)]\tLoss: 1.952567\n",
      "\n",
      "Test set: Average loss: 1.9725, Accuracy: 316/2708 (12%)\n",
      "\n",
      "Train Epoch: 40 [0/2708 (0%)]\tLoss: 2.000331\n",
      "Train Epoch: 40 [640/2708 (23%)]\tLoss: 1.995149\n",
      "Train Epoch: 40 [1280/2708 (47%)]\tLoss: 1.977517\n",
      "Train Epoch: 40 [1920/2708 (70%)]\tLoss: 1.941975\n",
      "Train Epoch: 40 [2560/2708 (93%)]\tLoss: 1.953715\n",
      "\n",
      "Test set: Average loss: 1.9680, Accuracy: 349/2708 (13%)\n",
      "\n",
      "Train Epoch: 41 [0/2708 (0%)]\tLoss: 2.008571\n",
      "Train Epoch: 41 [640/2708 (23%)]\tLoss: 1.954990\n",
      "Train Epoch: 41 [1280/2708 (47%)]\tLoss: 1.954091\n",
      "Train Epoch: 41 [1920/2708 (70%)]\tLoss: 1.973386\n",
      "Train Epoch: 41 [2560/2708 (93%)]\tLoss: 1.960347\n",
      "\n",
      "Test set: Average loss: 1.9720, Accuracy: 307/2708 (11%)\n",
      "\n",
      "Train Epoch: 42 [0/2708 (0%)]\tLoss: 2.045594\n",
      "Train Epoch: 42 [640/2708 (23%)]\tLoss: 1.981997\n",
      "Train Epoch: 42 [1280/2708 (47%)]\tLoss: 1.990829\n",
      "Train Epoch: 42 [1920/2708 (70%)]\tLoss: 1.983881\n",
      "Train Epoch: 42 [2560/2708 (93%)]\tLoss: 1.954024\n",
      "\n",
      "Test set: Average loss: 1.9700, Accuracy: 345/2708 (13%)\n",
      "\n",
      "Train Epoch: 43 [0/2708 (0%)]\tLoss: 1.956978\n",
      "Train Epoch: 43 [640/2708 (23%)]\tLoss: 1.971714\n",
      "Train Epoch: 43 [1280/2708 (47%)]\tLoss: 1.974905\n",
      "Train Epoch: 43 [1920/2708 (70%)]\tLoss: 1.984402\n",
      "Train Epoch: 43 [2560/2708 (93%)]\tLoss: 1.975108\n",
      "\n",
      "Test set: Average loss: 1.9761, Accuracy: 322/2708 (12%)\n",
      "\n",
      "Train Epoch: 44 [0/2708 (0%)]\tLoss: 2.099684\n",
      "Train Epoch: 44 [640/2708 (23%)]\tLoss: 1.991179\n",
      "Train Epoch: 44 [1280/2708 (47%)]\tLoss: 2.003840\n",
      "Train Epoch: 44 [1920/2708 (70%)]\tLoss: 1.956378\n",
      "Train Epoch: 44 [2560/2708 (93%)]\tLoss: 1.966051\n",
      "\n",
      "Test set: Average loss: 1.9714, Accuracy: 330/2708 (12%)\n",
      "\n",
      "Train Epoch: 45 [0/2708 (0%)]\tLoss: 2.093170\n",
      "Train Epoch: 45 [640/2708 (23%)]\tLoss: 1.954989\n",
      "Train Epoch: 45 [1280/2708 (47%)]\tLoss: 1.970508\n",
      "Train Epoch: 45 [1920/2708 (70%)]\tLoss: 1.950980\n",
      "Train Epoch: 45 [2560/2708 (93%)]\tLoss: 1.974665\n",
      "\n",
      "Test set: Average loss: 1.9734, Accuracy: 357/2708 (13%)\n",
      "\n",
      "Train Epoch: 46 [0/2708 (0%)]\tLoss: 2.021518\n",
      "Train Epoch: 46 [640/2708 (23%)]\tLoss: 1.964705\n",
      "Train Epoch: 46 [1280/2708 (47%)]\tLoss: 1.984758\n",
      "Train Epoch: 46 [1920/2708 (70%)]\tLoss: 1.972775\n",
      "Train Epoch: 46 [2560/2708 (93%)]\tLoss: 1.953053\n",
      "\n",
      "Test set: Average loss: 1.9712, Accuracy: 329/2708 (12%)\n",
      "\n",
      "Train Epoch: 47 [0/2708 (0%)]\tLoss: 2.101246\n",
      "Train Epoch: 47 [640/2708 (23%)]\tLoss: 1.955564\n",
      "Train Epoch: 47 [1280/2708 (47%)]\tLoss: 1.976272\n",
      "Train Epoch: 47 [1920/2708 (70%)]\tLoss: 1.966783\n",
      "Train Epoch: 47 [2560/2708 (93%)]\tLoss: 1.970468\n",
      "\n",
      "Test set: Average loss: 1.9711, Accuracy: 332/2708 (12%)\n",
      "\n",
      "Train Epoch: 48 [0/2708 (0%)]\tLoss: 2.046762\n",
      "Train Epoch: 48 [640/2708 (23%)]\tLoss: 1.977396\n",
      "Train Epoch: 48 [1280/2708 (47%)]\tLoss: 1.955727\n",
      "Train Epoch: 48 [1920/2708 (70%)]\tLoss: 1.968968\n",
      "Train Epoch: 48 [2560/2708 (93%)]\tLoss: 1.933902\n",
      "\n",
      "Test set: Average loss: 1.9692, Accuracy: 338/2708 (12%)\n",
      "\n",
      "Train Epoch: 49 [0/2708 (0%)]\tLoss: 2.045374\n",
      "Train Epoch: 49 [640/2708 (23%)]\tLoss: 2.000748\n",
      "Train Epoch: 49 [1280/2708 (47%)]\tLoss: 1.965568\n",
      "Train Epoch: 49 [1920/2708 (70%)]\tLoss: 1.967636\n",
      "Train Epoch: 49 [2560/2708 (93%)]\tLoss: 1.970238\n",
      "\n",
      "Test set: Average loss: 1.9661, Accuracy: 342/2708 (13%)\n",
      "\n",
      "Train Epoch: 50 [0/2708 (0%)]\tLoss: 1.970706\n",
      "Train Epoch: 50 [640/2708 (23%)]\tLoss: 1.980717\n",
      "Train Epoch: 50 [1280/2708 (47%)]\tLoss: 1.964804\n",
      "Train Epoch: 50 [1920/2708 (70%)]\tLoss: 1.958851\n",
      "Train Epoch: 50 [2560/2708 (93%)]\tLoss: 1.952654\n",
      "\n",
      "Test set: Average loss: 1.9709, Accuracy: 339/2708 (13%)\n",
      "\n",
      "Train Epoch: 51 [0/2708 (0%)]\tLoss: 2.037565\n",
      "Train Epoch: 51 [640/2708 (23%)]\tLoss: 1.991518\n",
      "Train Epoch: 51 [1280/2708 (47%)]\tLoss: 2.006321\n",
      "Train Epoch: 51 [1920/2708 (70%)]\tLoss: 1.949504\n",
      "Train Epoch: 51 [2560/2708 (93%)]\tLoss: 1.954033\n",
      "\n",
      "Test set: Average loss: 1.9703, Accuracy: 332/2708 (12%)\n",
      "\n",
      "Train Epoch: 52 [0/2708 (0%)]\tLoss: 1.920803\n",
      "Train Epoch: 52 [640/2708 (23%)]\tLoss: 1.987975\n",
      "Train Epoch: 52 [1280/2708 (47%)]\tLoss: 1.953767\n",
      "Train Epoch: 52 [1920/2708 (70%)]\tLoss: 1.965832\n",
      "Train Epoch: 52 [2560/2708 (93%)]\tLoss: 1.951960\n",
      "\n",
      "Test set: Average loss: 1.9747, Accuracy: 325/2708 (12%)\n",
      "\n",
      "Train Epoch: 53 [0/2708 (0%)]\tLoss: 2.057186\n",
      "Train Epoch: 53 [640/2708 (23%)]\tLoss: 1.987145\n",
      "Train Epoch: 53 [1280/2708 (47%)]\tLoss: 2.011621\n",
      "Train Epoch: 53 [1920/2708 (70%)]\tLoss: 1.966181\n",
      "Train Epoch: 53 [2560/2708 (93%)]\tLoss: 1.965615\n",
      "\n",
      "Test set: Average loss: 1.9699, Accuracy: 335/2708 (12%)\n",
      "\n",
      "Train Epoch: 54 [0/2708 (0%)]\tLoss: 2.008285\n",
      "Train Epoch: 54 [640/2708 (23%)]\tLoss: 1.969088\n",
      "Train Epoch: 54 [1280/2708 (47%)]\tLoss: 1.974128\n",
      "Train Epoch: 54 [1920/2708 (70%)]\tLoss: 1.977274\n",
      "Train Epoch: 54 [2560/2708 (93%)]\tLoss: 1.944356\n",
      "\n",
      "Test set: Average loss: 1.9713, Accuracy: 333/2708 (12%)\n",
      "\n",
      "Train Epoch: 55 [0/2708 (0%)]\tLoss: 1.996605\n",
      "Train Epoch: 55 [640/2708 (23%)]\tLoss: 1.973128\n",
      "Train Epoch: 55 [1280/2708 (47%)]\tLoss: 1.996829\n",
      "Train Epoch: 55 [1920/2708 (70%)]\tLoss: 1.975752\n",
      "Train Epoch: 55 [2560/2708 (93%)]\tLoss: 1.960618\n",
      "\n",
      "Test set: Average loss: 1.9741, Accuracy: 330/2708 (12%)\n",
      "\n",
      "Train Epoch: 56 [0/2708 (0%)]\tLoss: 1.997741\n",
      "Train Epoch: 56 [640/2708 (23%)]\tLoss: 1.986213\n",
      "Train Epoch: 56 [1280/2708 (47%)]\tLoss: 1.996134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 56 [1920/2708 (70%)]\tLoss: 1.966723\n",
      "Train Epoch: 56 [2560/2708 (93%)]\tLoss: 1.960735\n",
      "\n",
      "Test set: Average loss: 1.9723, Accuracy: 311/2708 (11%)\n",
      "\n",
      "Train Epoch: 57 [0/2708 (0%)]\tLoss: 2.085795\n",
      "Train Epoch: 57 [640/2708 (23%)]\tLoss: 1.970841\n",
      "Train Epoch: 57 [1280/2708 (47%)]\tLoss: 1.959633\n",
      "Train Epoch: 57 [1920/2708 (70%)]\tLoss: 1.960894\n",
      "Train Epoch: 57 [2560/2708 (93%)]\tLoss: 1.985427\n",
      "\n",
      "Test set: Average loss: 1.9728, Accuracy: 317/2708 (12%)\n",
      "\n",
      "Train Epoch: 58 [0/2708 (0%)]\tLoss: 2.067924\n",
      "Train Epoch: 58 [640/2708 (23%)]\tLoss: 1.976116\n",
      "Train Epoch: 58 [1280/2708 (47%)]\tLoss: 1.954110\n",
      "Train Epoch: 58 [1920/2708 (70%)]\tLoss: 1.955208\n",
      "Train Epoch: 58 [2560/2708 (93%)]\tLoss: 1.953291\n",
      "\n",
      "Test set: Average loss: 1.9731, Accuracy: 314/2708 (12%)\n",
      "\n",
      "Train Epoch: 59 [0/2708 (0%)]\tLoss: 2.030685\n",
      "Train Epoch: 59 [640/2708 (23%)]\tLoss: 1.995131\n",
      "Train Epoch: 59 [1280/2708 (47%)]\tLoss: 1.994605\n",
      "Train Epoch: 59 [1920/2708 (70%)]\tLoss: 1.978620\n",
      "Train Epoch: 59 [2560/2708 (93%)]\tLoss: 1.956326\n",
      "\n",
      "Test set: Average loss: 1.9694, Accuracy: 342/2708 (13%)\n",
      "\n",
      "Train Epoch: 60 [0/2708 (0%)]\tLoss: 1.994501\n",
      "Train Epoch: 60 [640/2708 (23%)]\tLoss: 2.000918\n",
      "Train Epoch: 60 [1280/2708 (47%)]\tLoss: 1.961913\n",
      "Train Epoch: 60 [1920/2708 (70%)]\tLoss: 1.953705\n",
      "Train Epoch: 60 [2560/2708 (93%)]\tLoss: 1.973480\n",
      "\n",
      "Test set: Average loss: 1.9692, Accuracy: 353/2708 (13%)\n",
      "\n",
      "Train Epoch: 61 [0/2708 (0%)]\tLoss: 2.004770\n",
      "Train Epoch: 61 [640/2708 (23%)]\tLoss: 2.002245\n",
      "Train Epoch: 61 [1280/2708 (47%)]\tLoss: 2.004640\n",
      "Train Epoch: 61 [1920/2708 (70%)]\tLoss: 1.976522\n",
      "Train Epoch: 61 [2560/2708 (93%)]\tLoss: 1.965489\n",
      "\n",
      "Test set: Average loss: 1.9731, Accuracy: 311/2708 (11%)\n",
      "\n",
      "Train Epoch: 62 [0/2708 (0%)]\tLoss: 2.006416\n",
      "Train Epoch: 62 [640/2708 (23%)]\tLoss: 1.965219\n",
      "Train Epoch: 62 [1280/2708 (47%)]\tLoss: 1.982659\n",
      "Train Epoch: 62 [1920/2708 (70%)]\tLoss: 1.969935\n",
      "Train Epoch: 62 [2560/2708 (93%)]\tLoss: 1.969425\n",
      "\n",
      "Test set: Average loss: 1.9740, Accuracy: 332/2708 (12%)\n",
      "\n",
      "Train Epoch: 63 [0/2708 (0%)]\tLoss: 1.945352\n",
      "Train Epoch: 63 [640/2708 (23%)]\tLoss: 1.985621\n",
      "Train Epoch: 63 [1280/2708 (47%)]\tLoss: 2.012854\n",
      "Train Epoch: 63 [1920/2708 (70%)]\tLoss: 1.956228\n",
      "Train Epoch: 63 [2560/2708 (93%)]\tLoss: 1.974223\n",
      "\n",
      "Test set: Average loss: 1.9715, Accuracy: 339/2708 (13%)\n",
      "\n",
      "Train Epoch: 64 [0/2708 (0%)]\tLoss: 2.067598\n",
      "Train Epoch: 64 [640/2708 (23%)]\tLoss: 1.963184\n",
      "Train Epoch: 64 [1280/2708 (47%)]\tLoss: 1.974556\n",
      "Train Epoch: 64 [1920/2708 (70%)]\tLoss: 1.943568\n",
      "Train Epoch: 64 [2560/2708 (93%)]\tLoss: 1.951275\n",
      "\n",
      "Test set: Average loss: 1.9761, Accuracy: 333/2708 (12%)\n",
      "\n",
      "Train Epoch: 65 [0/2708 (0%)]\tLoss: 2.046808\n",
      "Train Epoch: 65 [640/2708 (23%)]\tLoss: 1.953927\n",
      "Train Epoch: 65 [1280/2708 (47%)]\tLoss: 2.001913\n",
      "Train Epoch: 65 [1920/2708 (70%)]\tLoss: 1.936873\n",
      "Train Epoch: 65 [2560/2708 (93%)]\tLoss: 1.975462\n",
      "\n",
      "Test set: Average loss: 1.9657, Accuracy: 330/2708 (12%)\n",
      "\n",
      "Train Epoch: 66 [0/2708 (0%)]\tLoss: 2.013768\n",
      "Train Epoch: 66 [640/2708 (23%)]\tLoss: 1.954587\n",
      "Train Epoch: 66 [1280/2708 (47%)]\tLoss: 1.962902\n",
      "Train Epoch: 66 [1920/2708 (70%)]\tLoss: 1.982403\n",
      "Train Epoch: 66 [2560/2708 (93%)]\tLoss: 1.963742\n",
      "\n",
      "Test set: Average loss: 1.9736, Accuracy: 298/2708 (11%)\n",
      "\n",
      "Train Epoch: 67 [0/2708 (0%)]\tLoss: 1.957835\n",
      "Train Epoch: 67 [640/2708 (23%)]\tLoss: 1.980536\n",
      "Train Epoch: 67 [1280/2708 (47%)]\tLoss: 1.983519\n",
      "Train Epoch: 67 [1920/2708 (70%)]\tLoss: 1.971609\n",
      "Train Epoch: 67 [2560/2708 (93%)]\tLoss: 1.962896\n",
      "\n",
      "Test set: Average loss: 1.9719, Accuracy: 350/2708 (13%)\n",
      "\n",
      "Train Epoch: 68 [0/2708 (0%)]\tLoss: 1.948557\n",
      "Train Epoch: 68 [640/2708 (23%)]\tLoss: 1.969022\n",
      "Train Epoch: 68 [1280/2708 (47%)]\tLoss: 1.979121\n",
      "Train Epoch: 68 [1920/2708 (70%)]\tLoss: 1.963997\n",
      "Train Epoch: 68 [2560/2708 (93%)]\tLoss: 1.948875\n",
      "\n",
      "Test set: Average loss: 1.9674, Accuracy: 334/2708 (12%)\n",
      "\n",
      "Train Epoch: 69 [0/2708 (0%)]\tLoss: 2.016659\n",
      "Train Epoch: 69 [640/2708 (23%)]\tLoss: 1.989483\n",
      "Train Epoch: 69 [1280/2708 (47%)]\tLoss: 2.002710\n",
      "Train Epoch: 69 [1920/2708 (70%)]\tLoss: 1.942879\n",
      "Train Epoch: 69 [2560/2708 (93%)]\tLoss: 1.951810\n",
      "\n",
      "Test set: Average loss: 1.9725, Accuracy: 332/2708 (12%)\n",
      "\n",
      "Train Epoch: 70 [0/2708 (0%)]\tLoss: 1.963372\n",
      "Train Epoch: 70 [640/2708 (23%)]\tLoss: 1.985724\n",
      "Train Epoch: 70 [1280/2708 (47%)]\tLoss: 1.974179\n",
      "Train Epoch: 70 [1920/2708 (70%)]\tLoss: 1.954630\n",
      "Train Epoch: 70 [2560/2708 (93%)]\tLoss: 1.999781\n",
      "\n",
      "Test set: Average loss: 1.9730, Accuracy: 330/2708 (12%)\n",
      "\n",
      "Train Epoch: 71 [0/2708 (0%)]\tLoss: 2.058470\n",
      "Train Epoch: 71 [640/2708 (23%)]\tLoss: 1.969996\n",
      "Train Epoch: 71 [1280/2708 (47%)]\tLoss: 1.959471\n",
      "Train Epoch: 71 [1920/2708 (70%)]\tLoss: 1.951045\n",
      "Train Epoch: 71 [2560/2708 (93%)]\tLoss: 1.973449\n",
      "\n",
      "Test set: Average loss: 1.9713, Accuracy: 338/2708 (12%)\n",
      "\n",
      "Train Epoch: 72 [0/2708 (0%)]\tLoss: 2.015250\n",
      "Train Epoch: 72 [640/2708 (23%)]\tLoss: 1.980212\n",
      "Train Epoch: 72 [1280/2708 (47%)]\tLoss: 1.991135\n",
      "Train Epoch: 72 [1920/2708 (70%)]\tLoss: 1.941279\n",
      "Train Epoch: 72 [2560/2708 (93%)]\tLoss: 1.987759\n",
      "\n",
      "Test set: Average loss: 1.9727, Accuracy: 306/2708 (11%)\n",
      "\n",
      "Train Epoch: 73 [0/2708 (0%)]\tLoss: 1.966580\n",
      "Train Epoch: 73 [640/2708 (23%)]\tLoss: 1.994715\n",
      "Train Epoch: 73 [1280/2708 (47%)]\tLoss: 1.999423\n",
      "Train Epoch: 73 [1920/2708 (70%)]\tLoss: 1.954254\n",
      "Train Epoch: 73 [2560/2708 (93%)]\tLoss: 1.970803\n",
      "\n",
      "Test set: Average loss: 1.9714, Accuracy: 322/2708 (12%)\n",
      "\n",
      "Train Epoch: 74 [0/2708 (0%)]\tLoss: 1.960299\n",
      "Train Epoch: 74 [640/2708 (23%)]\tLoss: 1.948466\n",
      "Train Epoch: 74 [1280/2708 (47%)]\tLoss: 2.026865\n",
      "Train Epoch: 74 [1920/2708 (70%)]\tLoss: 1.952291\n",
      "Train Epoch: 74 [2560/2708 (93%)]\tLoss: 1.958270\n",
      "\n",
      "Test set: Average loss: 1.9692, Accuracy: 352/2708 (13%)\n",
      "\n",
      "Train Epoch: 75 [0/2708 (0%)]\tLoss: 2.044092\n",
      "Train Epoch: 75 [640/2708 (23%)]\tLoss: 1.980752\n",
      "Train Epoch: 75 [1280/2708 (47%)]\tLoss: 1.993436\n",
      "Train Epoch: 75 [1920/2708 (70%)]\tLoss: 1.959565\n",
      "Train Epoch: 75 [2560/2708 (93%)]\tLoss: 1.961182\n",
      "\n",
      "Test set: Average loss: 1.9686, Accuracy: 335/2708 (12%)\n",
      "\n",
      "Train Epoch: 76 [0/2708 (0%)]\tLoss: 2.061051\n",
      "Train Epoch: 76 [640/2708 (23%)]\tLoss: 1.995849\n",
      "Train Epoch: 76 [1280/2708 (47%)]\tLoss: 1.986659\n",
      "Train Epoch: 76 [1920/2708 (70%)]\tLoss: 1.968989\n",
      "Train Epoch: 76 [2560/2708 (93%)]\tLoss: 1.946150\n",
      "\n",
      "Test set: Average loss: 1.9717, Accuracy: 322/2708 (12%)\n",
      "\n",
      "Train Epoch: 77 [0/2708 (0%)]\tLoss: 2.025233\n",
      "Train Epoch: 77 [640/2708 (23%)]\tLoss: 1.977583\n",
      "Train Epoch: 77 [1280/2708 (47%)]\tLoss: 2.007476\n",
      "Train Epoch: 77 [1920/2708 (70%)]\tLoss: 1.946664\n",
      "Train Epoch: 77 [2560/2708 (93%)]\tLoss: 1.976997\n",
      "\n",
      "Test set: Average loss: 1.9699, Accuracy: 309/2708 (11%)\n",
      "\n",
      "Train Epoch: 78 [0/2708 (0%)]\tLoss: 1.945247\n",
      "Train Epoch: 78 [640/2708 (23%)]\tLoss: 1.976358\n",
      "Train Epoch: 78 [1280/2708 (47%)]\tLoss: 1.969450\n",
      "Train Epoch: 78 [1920/2708 (70%)]\tLoss: 1.959386\n",
      "Train Epoch: 78 [2560/2708 (93%)]\tLoss: 1.976805\n",
      "\n",
      "Test set: Average loss: 1.9752, Accuracy: 340/2708 (13%)\n",
      "\n",
      "Train Epoch: 79 [0/2708 (0%)]\tLoss: 1.914781\n",
      "Train Epoch: 79 [640/2708 (23%)]\tLoss: 1.971155\n",
      "Train Epoch: 79 [1280/2708 (47%)]\tLoss: 1.949606\n",
      "Train Epoch: 79 [1920/2708 (70%)]\tLoss: 1.968653\n",
      "Train Epoch: 79 [2560/2708 (93%)]\tLoss: 1.954697\n",
      "\n",
      "Test set: Average loss: 1.9681, Accuracy: 355/2708 (13%)\n",
      "\n",
      "Train Epoch: 80 [0/2708 (0%)]\tLoss: 2.018197\n",
      "Train Epoch: 80 [640/2708 (23%)]\tLoss: 1.974656\n",
      "Train Epoch: 80 [1280/2708 (47%)]\tLoss: 1.991668\n",
      "Train Epoch: 80 [1920/2708 (70%)]\tLoss: 1.955333\n",
      "Train Epoch: 80 [2560/2708 (93%)]\tLoss: 1.954808\n",
      "\n",
      "Test set: Average loss: 1.9731, Accuracy: 318/2708 (12%)\n",
      "\n",
      "Train Epoch: 81 [0/2708 (0%)]\tLoss: 1.981004\n",
      "Train Epoch: 81 [640/2708 (23%)]\tLoss: 1.949904\n",
      "Train Epoch: 81 [1280/2708 (47%)]\tLoss: 1.978918\n",
      "Train Epoch: 81 [1920/2708 (70%)]\tLoss: 1.947745\n",
      "Train Epoch: 81 [2560/2708 (93%)]\tLoss: 1.965417\n",
      "\n",
      "Test set: Average loss: 1.9708, Accuracy: 336/2708 (12%)\n",
      "\n",
      "Train Epoch: 82 [0/2708 (0%)]\tLoss: 2.022451\n",
      "Train Epoch: 82 [640/2708 (23%)]\tLoss: 1.978454\n",
      "Train Epoch: 82 [1280/2708 (47%)]\tLoss: 1.964355\n",
      "Train Epoch: 82 [1920/2708 (70%)]\tLoss: 1.946535\n",
      "Train Epoch: 82 [2560/2708 (93%)]\tLoss: 1.975729\n",
      "\n",
      "Test set: Average loss: 1.9677, Accuracy: 341/2708 (13%)\n",
      "\n",
      "Train Epoch: 83 [0/2708 (0%)]\tLoss: 2.077145\n",
      "Train Epoch: 83 [640/2708 (23%)]\tLoss: 1.985109\n",
      "Train Epoch: 83 [1280/2708 (47%)]\tLoss: 1.984181\n",
      "Train Epoch: 83 [1920/2708 (70%)]\tLoss: 1.965579\n",
      "Train Epoch: 83 [2560/2708 (93%)]\tLoss: 1.989022\n",
      "\n",
      "Test set: Average loss: 1.9742, Accuracy: 324/2708 (12%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 84 [0/2708 (0%)]\tLoss: 1.945428\n",
      "Train Epoch: 84 [640/2708 (23%)]\tLoss: 1.968040\n",
      "Train Epoch: 84 [1280/2708 (47%)]\tLoss: 1.969968\n",
      "Train Epoch: 84 [1920/2708 (70%)]\tLoss: 1.979414\n",
      "Train Epoch: 84 [2560/2708 (93%)]\tLoss: 1.938646\n",
      "\n",
      "Test set: Average loss: 1.9721, Accuracy: 351/2708 (13%)\n",
      "\n",
      "Train Epoch: 85 [0/2708 (0%)]\tLoss: 2.016450\n",
      "Train Epoch: 85 [640/2708 (23%)]\tLoss: 1.953452\n",
      "Train Epoch: 85 [1280/2708 (47%)]\tLoss: 2.006234\n",
      "Train Epoch: 85 [1920/2708 (70%)]\tLoss: 1.997195\n",
      "Train Epoch: 85 [2560/2708 (93%)]\tLoss: 1.946887\n",
      "\n",
      "Test set: Average loss: 1.9779, Accuracy: 302/2708 (11%)\n",
      "\n",
      "Train Epoch: 86 [0/2708 (0%)]\tLoss: 1.998552\n",
      "Train Epoch: 86 [640/2708 (23%)]\tLoss: 1.948653\n",
      "Train Epoch: 86 [1280/2708 (47%)]\tLoss: 2.007052\n",
      "Train Epoch: 86 [1920/2708 (70%)]\tLoss: 1.957553\n",
      "Train Epoch: 86 [2560/2708 (93%)]\tLoss: 1.960881\n",
      "\n",
      "Test set: Average loss: 1.9702, Accuracy: 338/2708 (12%)\n",
      "\n",
      "Train Epoch: 87 [0/2708 (0%)]\tLoss: 2.015155\n",
      "Train Epoch: 87 [640/2708 (23%)]\tLoss: 1.946390\n",
      "Train Epoch: 87 [1280/2708 (47%)]\tLoss: 2.005342\n",
      "Train Epoch: 87 [1920/2708 (70%)]\tLoss: 1.960409\n",
      "Train Epoch: 87 [2560/2708 (93%)]\tLoss: 1.955846\n",
      "\n",
      "Test set: Average loss: 1.9721, Accuracy: 320/2708 (12%)\n",
      "\n",
      "Train Epoch: 88 [0/2708 (0%)]\tLoss: 1.982181\n",
      "Train Epoch: 88 [640/2708 (23%)]\tLoss: 1.988193\n",
      "Train Epoch: 88 [1280/2708 (47%)]\tLoss: 1.965275\n",
      "Train Epoch: 88 [1920/2708 (70%)]\tLoss: 1.959115\n",
      "Train Epoch: 88 [2560/2708 (93%)]\tLoss: 1.978266\n",
      "\n",
      "Test set: Average loss: 1.9714, Accuracy: 338/2708 (12%)\n",
      "\n",
      "Train Epoch: 89 [0/2708 (0%)]\tLoss: 1.913850\n",
      "Train Epoch: 89 [640/2708 (23%)]\tLoss: 1.980044\n",
      "Train Epoch: 89 [1280/2708 (47%)]\tLoss: 1.964455\n",
      "Train Epoch: 89 [1920/2708 (70%)]\tLoss: 1.981125\n",
      "Train Epoch: 89 [2560/2708 (93%)]\tLoss: 1.966924\n",
      "\n",
      "Test set: Average loss: 1.9712, Accuracy: 333/2708 (12%)\n",
      "\n",
      "Train Epoch: 90 [0/2708 (0%)]\tLoss: 2.034439\n",
      "Train Epoch: 90 [640/2708 (23%)]\tLoss: 1.995508\n",
      "Train Epoch: 90 [1280/2708 (47%)]\tLoss: 1.966100\n",
      "Train Epoch: 90 [1920/2708 (70%)]\tLoss: 1.959566\n",
      "Train Epoch: 90 [2560/2708 (93%)]\tLoss: 1.945632\n",
      "\n",
      "Test set: Average loss: 1.9714, Accuracy: 331/2708 (12%)\n",
      "\n",
      "Train Epoch: 91 [0/2708 (0%)]\tLoss: 2.050558\n",
      "Train Epoch: 91 [640/2708 (23%)]\tLoss: 2.010606\n",
      "Train Epoch: 91 [1280/2708 (47%)]\tLoss: 2.001989\n",
      "Train Epoch: 91 [1920/2708 (70%)]\tLoss: 1.978966\n",
      "Train Epoch: 91 [2560/2708 (93%)]\tLoss: 1.972117\n",
      "\n",
      "Test set: Average loss: 1.9728, Accuracy: 311/2708 (11%)\n",
      "\n",
      "Train Epoch: 92 [0/2708 (0%)]\tLoss: 1.997765\n",
      "Train Epoch: 92 [640/2708 (23%)]\tLoss: 1.962649\n",
      "Train Epoch: 92 [1280/2708 (47%)]\tLoss: 1.998726\n",
      "Train Epoch: 92 [1920/2708 (70%)]\tLoss: 1.957644\n",
      "Train Epoch: 92 [2560/2708 (93%)]\tLoss: 1.948419\n",
      "\n",
      "Test set: Average loss: 1.9767, Accuracy: 310/2708 (11%)\n",
      "\n",
      "Train Epoch: 93 [0/2708 (0%)]\tLoss: 1.943150\n",
      "Train Epoch: 93 [640/2708 (23%)]\tLoss: 1.975746\n",
      "Train Epoch: 93 [1280/2708 (47%)]\tLoss: 1.987728\n",
      "Train Epoch: 93 [1920/2708 (70%)]\tLoss: 1.965321\n",
      "Train Epoch: 93 [2560/2708 (93%)]\tLoss: 1.985262\n",
      "\n",
      "Test set: Average loss: 1.9725, Accuracy: 347/2708 (13%)\n",
      "\n",
      "Train Epoch: 94 [0/2708 (0%)]\tLoss: 2.058379\n",
      "Train Epoch: 94 [640/2708 (23%)]\tLoss: 1.956549\n",
      "Train Epoch: 94 [1280/2708 (47%)]\tLoss: 2.003359\n",
      "Train Epoch: 94 [1920/2708 (70%)]\tLoss: 1.986459\n",
      "Train Epoch: 94 [2560/2708 (93%)]\tLoss: 1.968412\n",
      "\n",
      "Test set: Average loss: 1.9688, Accuracy: 342/2708 (13%)\n",
      "\n",
      "Train Epoch: 95 [0/2708 (0%)]\tLoss: 2.053306\n",
      "Train Epoch: 95 [640/2708 (23%)]\tLoss: 1.960707\n",
      "Train Epoch: 95 [1280/2708 (47%)]\tLoss: 2.004015\n",
      "Train Epoch: 95 [1920/2708 (70%)]\tLoss: 1.942030\n",
      "Train Epoch: 95 [2560/2708 (93%)]\tLoss: 1.979548\n",
      "\n",
      "Test set: Average loss: 1.9737, Accuracy: 301/2708 (11%)\n",
      "\n",
      "Train Epoch: 96 [0/2708 (0%)]\tLoss: 1.938031\n",
      "Train Epoch: 96 [640/2708 (23%)]\tLoss: 1.990213\n",
      "Train Epoch: 96 [1280/2708 (47%)]\tLoss: 1.940485\n",
      "Train Epoch: 96 [1920/2708 (70%)]\tLoss: 1.967108\n",
      "Train Epoch: 96 [2560/2708 (93%)]\tLoss: 1.968056\n",
      "\n",
      "Test set: Average loss: 1.9728, Accuracy: 332/2708 (12%)\n",
      "\n",
      "Train Epoch: 97 [0/2708 (0%)]\tLoss: 2.047602\n",
      "Train Epoch: 97 [640/2708 (23%)]\tLoss: 1.974779\n",
      "Train Epoch: 97 [1280/2708 (47%)]\tLoss: 1.979251\n",
      "Train Epoch: 97 [1920/2708 (70%)]\tLoss: 1.964319\n",
      "Train Epoch: 97 [2560/2708 (93%)]\tLoss: 1.964612\n",
      "\n",
      "Test set: Average loss: 1.9709, Accuracy: 323/2708 (12%)\n",
      "\n",
      "Train Epoch: 98 [0/2708 (0%)]\tLoss: 2.038245\n",
      "Train Epoch: 98 [640/2708 (23%)]\tLoss: 1.959822\n",
      "Train Epoch: 98 [1280/2708 (47%)]\tLoss: 1.999073\n",
      "Train Epoch: 98 [1920/2708 (70%)]\tLoss: 1.949949\n",
      "Train Epoch: 98 [2560/2708 (93%)]\tLoss: 1.975832\n",
      "\n",
      "Test set: Average loss: 1.9670, Accuracy: 320/2708 (12%)\n",
      "\n",
      "Train Epoch: 99 [0/2708 (0%)]\tLoss: 2.028853\n",
      "Train Epoch: 99 [640/2708 (23%)]\tLoss: 1.942038\n",
      "Train Epoch: 99 [1280/2708 (47%)]\tLoss: 2.015882\n",
      "Train Epoch: 99 [1920/2708 (70%)]\tLoss: 1.983376\n",
      "Train Epoch: 99 [2560/2708 (93%)]\tLoss: 1.954368\n",
      "\n",
      "Test set: Average loss: 1.9704, Accuracy: 341/2708 (13%)\n",
      "\n",
      "Train Epoch: 100 [0/2708 (0%)]\tLoss: 1.940906\n",
      "Train Epoch: 100 [640/2708 (23%)]\tLoss: 1.957525\n",
      "Train Epoch: 100 [1280/2708 (47%)]\tLoss: 1.974847\n",
      "Train Epoch: 100 [1920/2708 (70%)]\tLoss: 1.966792\n",
      "Train Epoch: 100 [2560/2708 (93%)]\tLoss: 1.955052\n",
      "\n",
      "Test set: Average loss: 1.9710, Accuracy: 341/2708 (13%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GNN = one_layer_GraphNet(A,X)\n",
    "GNN_test_acc = []\n",
    "GNN.to(device)\n",
    "print(model)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-1)\n",
    "print('number of trainable parameters: %d' %\n",
    "          np.sum([np.prod(p.size()) if p.requires_grad else 0 for p in model.parameters()]))\n",
    "full_x = torch.tensor(X) # transform to torch tensor\n",
    "full_y = torch.from_numpy(y)\n",
    "full_y = full_y.type(torch.long)\n",
    "full_x = full_x.type(torch.long)\n",
    "\n",
    "cora_full_dataset = TensorDataset(full_x,full_y)\n",
    "cora_full_dataloader = DataLoader(cora_full_dataset, batch_size=64, shuffle=True, **kwargs)\n",
    "for epoch in range(1, 101):\n",
    "    train(GNN, device, cora_full_dataloader, optimizer)\n",
    "    accs = test(GNN, device, cora_full_dataloader)\n",
    "    GNN_test_acc.append(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(1, 101), GNN_test_acc, label = \"train_acc\")\n",
    "plt.legend()\n",
    "plt.title(\"GNN on Cora\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
